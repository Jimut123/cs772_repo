{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQhXczwl_TOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mostly torch imports and plot imports\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "# mostly torch imports and plot imports\n",
        "import torch\n",
        "import shutil\n",
        "import glob\n",
        "import pickle\n",
        "import random\n",
        "random.seed(42)\n",
        "# import colorama\n",
        "# from colorama import Fore, Style\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import torch.utils\n",
        "import torchvision\n",
        "from torch import optim\n",
        "import torch.distributions\n",
        "torch.manual_seed(42)\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "from matplotlib import rc, rcParams\n",
        "from numpy import sin\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('use_cuda: {}'.format(use_cuda))\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"Device to be used : \",device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REFSBVASE6fT",
        "outputId": "8c7e3ceb-c880-438f-d777-d9392998afa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use_cuda: True\n",
            "Device to be used :  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ClassificationNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ClassificationNetwork, self).__init__()\n",
        "        self.fc = nn.Linear(10, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the network\n",
        "model = ClassificationNetwork()"
      ],
      "metadata": {
        "id": "dtTOmVgsQf50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3sbX07sHUvcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B6jo9QiCUvYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Dataset):\n",
        "    def __init__(self, X_VALUES, Y_VALUES, choice):\n",
        "        self.X = X_VALUES\n",
        "        self.Y = Y_VALUES\n",
        "        self.choice = choice\n",
        "\n",
        "    def __get__number__(self, str_num):\n",
        "        return np.fromiter((int(bit) for bit in str_num), dtype=np.int8)\n",
        "\n",
        "    # NUMBER OF FILES IN THE DATASET\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    # GETTING SINGLE PAIR OF DATA\n",
        "    def __getitem__(self, idx):\n",
        "        # print(\"X = \",self.X)\n",
        "        # print(\"idx = \",idx)\n",
        "        X_numpy = self.__get__number__(self.X[idx])\n",
        "        X_numpy_reshaped = X_numpy.reshape((1, 10))\n",
        "        # print(\"X_numpy_reshaped = \", torch.FloatTensor(X_numpy_reshaped))\n",
        "        # print(\"Y = \", torch.FloatTensor(self.Y[idx]))\n",
        "        return torch.FloatTensor(X_numpy_reshaped), torch.FloatTensor(self.Y[idx])\n"
      ],
      "metadata": {
        "id": "FA4rjVUmE1PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(X_VALUES, Y_VALUES, choice=\"train\", batch_size=2, num_workers=10, shuffle=True):\n",
        "    dataset = DataGenerator(X_VALUES, Y_VALUES, choice=choice)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "# save checkpoint in pytorch\n",
        "def save_ckp(checkpoint, checkpoint_path):\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "\n",
        "# load checkpoint in pytorch\n",
        "def load_ckp(checkpoint_path, model, model_opt):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model_opt.load_state_dict(checkpoint['optimizer'])\n",
        "    return model, model_opt, checkpoint['epoch']"
      ],
      "metadata": {
        "id": "S8JVAT12QjfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_loader, model, optimizer, epoch):\n",
        "    print(\"\\n\\n---------------------------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "    progress_bar = tqdm(enumerate(train_loader))\n",
        "    total_loss = 0.0\n",
        "\n",
        "    N = 0\n",
        "    for step, (x, y) in progress_bar:\n",
        "        # if mask_1 is None and low_res_img is None:\n",
        "        #     continue\n",
        "        model.train()\n",
        "\n",
        "        #TRANSFERRING DATA TO DEVICE\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # clear the gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #GETTING THE PREDICTED IMAGE\n",
        "        print(\"x shape == \",x.shape)\n",
        "        pred_y = model.forward(x)\n",
        "\n",
        "        #LOSS FUNCTIONS\n",
        "        BCELOSS = nn.BCELoss()\n",
        "\n",
        "        #CALCULATING LOSSES\n",
        "        BCE_loss = BCELOSS(pred_y, y)\n",
        "\n",
        "        #LOSS TAKEN INTO CONSIDERATION\n",
        "        loss = BCE_loss\n",
        "\n",
        "\n",
        "        # CALCULATING METRICS\n",
        "        total_loss += loss\n",
        "\n",
        "        # print(loss)\n",
        "\n",
        "        #BACKPROPAGATING THE LOSS\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #DISPLAYING THE LOSS\n",
        "        progress_bar.set_description(\"Epoch: {} -  Loss: {} \".format(epoch, loss))\n",
        "\n",
        "\n",
        "    with open(\"history/train_logs.txt\", \"a\") as text_file:\n",
        "        text_file.write(\"{} {}\\n\".format(epoch, total_loss))\n",
        "\n",
        "    # print(\"Training Epoch: {} |  Total Loss: {} | Total Dice: {} | Total Jaccard: {} | N: {}\".format(epoch,total_loss, total_dice, total_jacard,N))\n",
        "    print(\"Training Epoch: {} |  Loss: {}\".format(epoch, total_loss))\n",
        "\n",
        "    return model, optimizer\n",
        "\n",
        "\n",
        "\n",
        "def test_epoch(test_loader, model, optimizer, epoch):\n",
        "\n",
        "    progress_bar = tqdm(enumerate(test_loader))\n",
        "    total_loss = 0.0\n",
        "\n",
        "    #SETTING THE NUMBER OF IMAGES TO CHECK AFTER EACH ITERATION\n",
        "    no_img_to_write = 20\n",
        "\n",
        "    total_loss = 0.0\n",
        "    for step, (x, y) in progress_bar:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "\n",
        "        #PREDICTED IMAGE\n",
        "        pred_y = model.forward(x)\n",
        "\n",
        "        #LOSS FUNCTIONS\n",
        "        BCELOSS = nn.BCELoss()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        #CALCULATING LOSSES\n",
        "        BCE_loss = BCELOSS(pred_y, y)\n",
        "\n",
        "        #LOSS TAKEN INTO CONSIDERATION\n",
        "        loss = BCE_loss\n",
        "\n",
        "        # CALCULATING METRICS\n",
        "        total_loss += loss\n",
        "\n",
        "\n",
        "        progress_bar.set_description(\"Epoch: {} -  Loss: {} \".format(epoch, total_loss))\n",
        "\n",
        "\n",
        "    with open(\"history/test_logs.txt\", \"a\") as text_file:\n",
        "        text_file.write(\"{} {}\\n\".format(epoch, total_loss))\n",
        "\n",
        "    print(\"Test Epoch: {} |  Loss: {}\".format(epoch, total_loss))\n",
        "    print(\"---------------------------------------------------------------------------------------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "id": "l0uyPRV1EbWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test(train_loader, test_loader, model, optimizer, n_epoch, resume):\n",
        "\n",
        "    #PATH TO SAVE THE CHECKPOINT\n",
        "    checkpoint_path = \"checkpoint/classification_net.pt\"\n",
        "\n",
        "    epoch = 0\n",
        "    #IF TRAINING IS TO RESUMED FROM A CERTAIN CHECKPOINT\n",
        "    if resume:\n",
        "        model, optimizer, epoch = load_ckp(\n",
        "            checkpoint_path, model, optimizer)\n",
        "\n",
        "    while epoch <= n_epoch:\n",
        "        epoch += 1\n",
        "        model, optimizer = train_epoch(train_loader, model, optimizer, epoch)\n",
        "\n",
        "        #CHECKPOINT CREATION\n",
        "        checkpoint = {'epoch': epoch+1, 'state_dict': model.state_dict(),\n",
        "                      'optimizer': optimizer.state_dict()}\n",
        "\n",
        "        #CHECKPOINT SAVING\n",
        "        save_ckp(checkpoint, checkpoint_path)\n",
        "        print(\"Checkpoint Saved\")\n",
        "\n",
        "    print(\"************************ Final Test Epoch *****************************\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_epoch(test_loader, model, optimizer, epoch)"
      ],
      "metadata": {
        "id": "TsSs6OojQpyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_pal(X):\n",
        "    return X == X[::-1]\n",
        "\n",
        "def generate_10_bit_binary_numbers():\n",
        "    binary_numbers = []\n",
        "\n",
        "    for i in range(2**10):\n",
        "        binary_str = format(i, '010b')\n",
        "        binary_numbers.append(binary_str)\n",
        "\n",
        "    return binary_numbers\n",
        "\n",
        "\n",
        "# Generate and store all 10-bit binary numbers\n",
        "binary_numbers_list = generate_10_bit_binary_numbers()\n",
        "\n",
        "\n",
        "Y_VALUES = []\n",
        "X_VALUES = []\n",
        "\n",
        "# Print and/or use the generated binary numbers as needed\n",
        "for binary_number in binary_numbers_list:\n",
        "    #print(binary_number)\n",
        "    if is_pal(binary_number) == True:\n",
        "        X_VALUES.append(binary_number)\n",
        "        Y_VALUES.append(1)\n",
        "    else:\n",
        "        X_VALUES.append(binary_number)\n",
        "        Y_VALUES.append(0)"
      ],
      "metadata": {
        "id": "RzxyrziZIH4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "\n",
        "    train_till = int(0.8*len(X_VALUES))\n",
        "\n",
        "    X_VALUES_TRAIN = X_VALUES[:train_till]\n",
        "    Y_VALUES_TRAIN = Y_VALUES[:train_till]\n",
        "\n",
        "    X_VALUES_TEST = X_VALUES[train_till:]\n",
        "    Y_VALUES_TEST = Y_VALUES[train_till:]\n",
        "\n",
        "    print(\"Total Number of Training data : \", len(X_VALUES_TRAIN))\n",
        "    print(\"Total Number of Testing data : \", len(X_VALUES_TEST))\n",
        "\n",
        "\n",
        "    # CREATING THE TRAIN LOADER\n",
        "    train_loader = load_data(\n",
        "        X_VALUES_TRAIN, Y_VALUES_TRAIN, choice=\"train\", batch_size=16, num_workers=1, shuffle=True)\n",
        "\n",
        "    # #CREATING THE TEST LOADER\n",
        "    test_loader = load_data(\n",
        "        X_VALUES_TEST, Y_VALUES_TEST, choice=\"test\", batch_size=1, num_workers=1, shuffle=False)\n",
        "\n",
        "    #CALLING THE MODEL\n",
        "    model = ClassificationNetwork()\n",
        "    model = model.to(device)\n",
        "\n",
        "    summary(model, input_size=(1, 10))\n",
        "\n",
        "    #DEFINING THE OPTIMIZER\n",
        "    optimizer = optim.Adam(\n",
        "        [p for p in model.parameters() if p.requires_grad], lr=1e-05, weight_decay=5e-4)\n",
        "\n",
        "    n_epoch = 200\n",
        "\n",
        "    #INDICATOR VARIABLE TO RESUME TRAINING OR START AFRESH\n",
        "    resume = False\n",
        "    train_val_test(train_loader, test_loader, model, optimizer, n_epoch, resume)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mCBgCFRa_TLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Starting the main function ----\")\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "2Ny9OMxJHfQA",
        "outputId": "e52b8a04-f161-4942-866a-ad95f6e4d403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting the main function ----\n",
            "Total Number of Training data :  819\n",
            "Total Number of Testing data :  205\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 1, 1]              11\n",
            "           Sigmoid-2                 [-1, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 11\n",
            "Trainable params: 11\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.00\n",
            "----------------------------------------------------------------\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape ==  torch.Size([16, 1, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Using a target size (torch.Size([16, 0])) that is different to the input size (torch.Size([16, 1, 1])) is deprecated. Please ensure they have the same size.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8cfdd70e811d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Starting the main function ----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-a18d4c847cda>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#INDICATOR VARIABLE TO RESUME TRAINING OR START AFRESH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mtrain_val_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-06277c98a935>\u001b[0m in \u001b[0;36mtrain_val_test\u001b[0;34m(train_loader, test_loader, model, optimizer, n_epoch, resume)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#CHECKPOINT CREATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-6f18d1daf324>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, optimizer, epoch)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#CALCULATING LOSSES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mBCE_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCELOSS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#LOSS TAKEN INTO CONSIDERATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3111\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3113\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3114\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([16, 0])) that is different to the input size (torch.Size([16, 1, 1])) is deprecated. Please ensure they have the same size."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([0., 0., 1., 0., 0., 1., 1., 1., 0., 1.])\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "62IFuDVSMs2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baaede2d-7960-43c8-edfe-cfe937e40618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W3Y25q5IUQIM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}