{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# mostly torch imports and plot imports\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "# mostly torch imports and plot imports\n",
        "import torch\n",
        "import shutil\n",
        "import glob\n",
        "import pickle\n",
        "import random\n",
        "random.seed(42)\n",
        "# import colorama\n",
        "# from colorama import Fore, Style\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import torch.utils\n",
        "import torchvision\n",
        "from torch import optim\n",
        "import torch.distributions\n",
        "torch.manual_seed(42)\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "from matplotlib import rc, rcParams\n",
        "from numpy import sin\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('use_cuda: {}'.format(use_cuda))\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"Device to be used : \",device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REFSBVASE6fT",
        "outputId": "e3b01cf3-5f42-4b22-981f-429e226d0ab9"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use_cuda: True\n",
            "Device to be used :  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ClassificationNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 512)\n",
        "        self.fc2 = nn.Linear(512,1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the network\n",
        "model = ClassificationNetwork()"
      ],
      "metadata": {
        "id": "dtTOmVgsQf50"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Dataset):\n",
        "    def __init__(self, X_VALUES, Y_VALUES, choice):\n",
        "        self.X = X_VALUES\n",
        "        self.Y = Y_VALUES\n",
        "        self.choice = choice\n",
        "\n",
        "    def __get__number__(self, str_num):\n",
        "        return np.fromiter((int(bit) for bit in str_num), dtype=np.int8)\n",
        "\n",
        "    # NUMBER OF FILES IN THE DATASET\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    # GETTING SINGLE PAIR OF DATA\n",
        "    def __getitem__(self, idx):\n",
        "        # print(\"X = \",self.X)\n",
        "        # print(\"idx = \",idx)\n",
        "        X_numpy = self.__get__number__(self.X[idx])\n",
        "        # X_numpy_reshaped = X_numpy.reshape((1, 10))\n",
        "        # print(\"X_numpy_reshaped = \", torch.FloatTensor(X_numpy_reshaped))\n",
        "        # print(\"Y = \", torch.FloatTensor(self.Y[idx]))\n",
        "        # return torch.FloatTensor(X_numpy_reshaped), torch.FloatTensor(self.Y[idx])\n",
        "        return torch.FloatTensor(X_numpy), self.Y[idx] #torch.FloatTensor(self.Y[idx])\n",
        "\n"
      ],
      "metadata": {
        "id": "FA4rjVUmE1PM"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(X_VALUES, Y_VALUES, choice=\"train\", batch_size=2, num_workers=10, shuffle=True):\n",
        "    dataset = DataGenerator(X_VALUES, Y_VALUES, choice=choice)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "# save checkpoint in pytorch\n",
        "def save_ckp(checkpoint, checkpoint_path):\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "\n",
        "# load checkpoint in pytorch\n",
        "def load_ckp(checkpoint_path, model, model_opt):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model_opt.load_state_dict(checkpoint['optimizer'])\n",
        "    return model, model_opt, checkpoint['epoch']"
      ],
      "metadata": {
        "id": "S8JVAT12QjfK"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(train_loader, model, optimizer, epoch):\n",
        "    print(\"\\n\\n---------------------------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "    progress_bar = tqdm(enumerate(train_loader))\n",
        "    total_loss = 0.0\n",
        "\n",
        "    N = 0\n",
        "    for step, (x, y) in progress_bar:\n",
        "        model.train()\n",
        "\n",
        "        #TRANSFERRING DATA TO DEVICE\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # clear the gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #GETTING THE PREDICTED IMAGE\n",
        "        # print(\"x shape == \",x.shape)\n",
        "        pred_y = model.forward(x)\n",
        "\n",
        "        # print (\"**************\")\n",
        "        # print (pred_y.shape)\n",
        "        y = y.unsqueeze(-1)\n",
        "        # print (y.shape)\n",
        "        # print (\"$$$$$$$$$$$$$$$\")\n",
        "        y = y.float()\n",
        "\n",
        "        #LOSS FUNCTIONS\n",
        "        BCELOSS = nn.BCELoss()\n",
        "\n",
        "        #CALCULATING LOSSES\n",
        "        BCE_loss = BCELOSS(pred_y, y)\n",
        "\n",
        "        # print (f'Prediction: {pred_y.item()} | {y.item()}')\n",
        "\n",
        "        #LOSS TAKEN INTO CONSIDERATION\n",
        "        loss = BCE_loss\n",
        "\n",
        "\n",
        "        # CALCULATING METRICS\n",
        "        total_loss += loss\n",
        "\n",
        "        # print(loss)\n",
        "\n",
        "        #BACKPROPAGATING THE LOSS\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #DISPLAYING THE LOSS\n",
        "        # progress_bar.set_description(\"Epoch: {} -  Loss: {} \".format(epoch, loss))\n",
        "\n",
        "\n",
        "    # with open(\"history/train_logs.txt\", \"a\") as text_file:\n",
        "    #     text_file.write(\"{} {}\\n\".format(epoch, total_loss))\n",
        "\n",
        "    # print(\"Training Epoch: {} |  Total Loss: {} | Total Dice: {} | Total Jaccard: {} | N: {}\".format(epoch,total_loss, total_dice, total_jacard,N))\n",
        "    print(\"Training Epoch: {} |  Loss: {}\".format(epoch, total_loss))\n",
        "\n",
        "    return model, optimizer\n",
        "\n",
        "\n",
        "\n",
        "def test_epoch(test_loader, model, optimizer, epoch):\n",
        "\n",
        "    progress_bar = tqdm(enumerate(test_loader))\n",
        "    total_loss = 0.0\n",
        "\n",
        "    #SETTING THE NUMBER OF IMAGES TO CHECK AFTER EACH ITERATION\n",
        "    no_img_to_write = 20\n",
        "\n",
        "    total_loss = 0.0\n",
        "    for step, (x, y) in progress_bar:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "\n",
        "        #PREDICTED IMAGE\n",
        "        pred_y = model.forward(x)\n",
        "\n",
        "        #LOSS FUNCTIONS\n",
        "        BCELOSS = nn.BCELoss()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        #CALCULATING LOSSES\n",
        "        BCE_loss = BCELOSS(pred_y, y)\n",
        "\n",
        "        #LOSS TAKEN INTO CONSIDERATION\n",
        "        loss = BCE_loss\n",
        "\n",
        "        # CALCULATING METRICS\n",
        "        total_loss += loss\n",
        "\n",
        "\n",
        "        # progress_bar.set_description(\"Epoch: {} -  Loss: {} \".format(epoch, total_loss))\n",
        "\n",
        "\n",
        "    # with open(\"history/test_logs.txt\", \"a\") as text_file:\n",
        "    #     text_file.write(\"{} {}\\n\".format(epoch, total_loss))\n",
        "\n",
        "    print(\"Test Epoch: {} |  Loss: {}\".format(epoch, total_loss))\n",
        "    print(\"---------------------------------------------------------------------------------------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "id": "l0uyPRV1EbWN"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test(train_loader, test_loader, model, optimizer, n_epoch, resume):\n",
        "\n",
        "    #PATH TO SAVE THE CHECKPOINT\n",
        "    checkpoint_path = \"classification_net.pt\"\n",
        "\n",
        "    epoch = 0\n",
        "    #IF TRAINING IS TO RESUMED FROM A CERTAIN CHECKPOINT\n",
        "    if resume:\n",
        "        model, optimizer, epoch = load_ckp(\n",
        "            checkpoint_path, model, optimizer)\n",
        "\n",
        "    while epoch <= n_epoch:\n",
        "        epoch += 1\n",
        "        model, optimizer = train_epoch(train_loader, model, optimizer, epoch)\n",
        "\n",
        "        #CHECKPOINT CREATION\n",
        "        checkpoint = {'epoch': epoch+1, 'state_dict': model.state_dict(),\n",
        "                      'optimizer': optimizer.state_dict()}\n",
        "\n",
        "        #CHECKPOINT SAVING\n",
        "        save_ckp(checkpoint, checkpoint_path)\n",
        "        print(\"Checkpoint Saved\")\n",
        "\n",
        "    print(\"************************ Final Test Epoch *****************************\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_epoch(test_loader, model, optimizer, epoch)"
      ],
      "metadata": {
        "id": "TsSs6OojQpyC"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_pal(X):\n",
        "    return X == X[::-1]\n",
        "\n",
        "def generate_10_bit_binary_numbers():\n",
        "    binary_numbers = []\n",
        "\n",
        "    for i in range(2**10):\n",
        "        binary_str = format(i, '010b')\n",
        "        binary_numbers.append(binary_str)\n",
        "\n",
        "    return binary_numbers\n",
        "\n",
        "\n",
        "# Generate and store all 10-bit binary numbers\n",
        "binary_numbers_list = generate_10_bit_binary_numbers()\n",
        "\n",
        "\n",
        "Y_VALUES = []\n",
        "X_VALUES = []\n",
        "\n",
        "# Print and/or use the generated binary numbers as needed\n",
        "for binary_number in binary_numbers_list:\n",
        "    #print(binary_number)\n",
        "    if is_pal(binary_number) == True:\n",
        "        X_VALUES.append(binary_number)\n",
        "        Y_VALUES.append(1)\n",
        "    else:\n",
        "        X_VALUES.append(binary_number)\n",
        "        Y_VALUES.append(0)"
      ],
      "metadata": {
        "id": "RzxyrziZIH4n"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.sum(np.array(Y_VALUES)==1)"
      ],
      "metadata": {
        "id": "ETeF-KYXAVGJ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.fromiter((int(bit) for bit in '10101'), dtype=np.int8)"
      ],
      "metadata": {
        "id": "ABNZvgapAx_T"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "\n",
        "    print ('modified!')\n",
        "\n",
        "    train_till = int(0.8*len(X_VALUES))\n",
        "\n",
        "    X_VALUES_TRAIN = X_VALUES[:train_till]\n",
        "    Y_VALUES_TRAIN = Y_VALUES[:train_till]\n",
        "\n",
        "    X_VALUES_TEST = X_VALUES[train_till:]\n",
        "    Y_VALUES_TEST = Y_VALUES[train_till:]\n",
        "\n",
        "    print(\"Total Number of Training data : \", len(X_VALUES_TRAIN))\n",
        "    print(\"Total Number of Testing data : \", len(X_VALUES_TEST))\n",
        "\n",
        "\n",
        "    # CREATING THE TRAIN LOADER\n",
        "    train_loader = load_data(\n",
        "        X_VALUES_TRAIN, Y_VALUES_TRAIN, choice=\"train\", batch_size=1, num_workers=1, shuffle=True)\n",
        "\n",
        "    # #CREATING THE TEST LOADER\n",
        "    test_loader = load_data(\n",
        "        X_VALUES_TEST, Y_VALUES_TEST, choice=\"test\", batch_size=1, num_workers=1, shuffle=False)\n",
        "\n",
        "    #CALLING THE MODEL\n",
        "    model = ClassificationNetwork()\n",
        "    model = model.to(device)\n",
        "\n",
        "    summary(model, input_size=(1, 10))\n",
        "\n",
        "    #DEFINING THE OPTIMIZER\n",
        "    optimizer = optim.Adam(\n",
        "        [p for p in model.parameters() if p.requires_grad], lr=1e-04, weight_decay=5e-4)\n",
        "\n",
        "    n_epoch = 200\n",
        "\n",
        "    #INDICATOR VARIABLE TO RESUME TRAINING OR START AFRESH\n",
        "    resume = False\n",
        "    train_val_test(train_loader, test_loader, model, optimizer, n_epoch, resume)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mCBgCFRa_TLQ"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Starting the main function ----\")\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2Ny9OMxJHfQA",
        "outputId": "b1d2a7f0-dd8b-42d4-f152-022a486543cf"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting the main function ----\n",
            "modified!\n",
            "Total Number of Training data :  819\n",
            "Total Number of Testing data :  205\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 512]           5,632\n",
            "            Linear-2                 [-1, 1, 1]             513\n",
            "           Sigmoid-3                 [-1, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 6,145\n",
            "Trainable params: 6,145\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 0.03\n",
            "----------------------------------------------------------------\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "819it [00:02, 340.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch: 1 |  Loss: 177.50595092773438\n",
            "Checkpoint Saved\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "819it [00:02, 302.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch: 2 |  Loss: 115.88270568847656\n",
            "Checkpoint Saved\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "819it [00:02, 334.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch: 3 |  Loss: 114.0158462524414\n",
            "Checkpoint Saved\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "819it [00:02, 337.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch: 4 |  Loss: 114.18791961669922\n",
            "Checkpoint Saved\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "819it [00:02, 340.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch: 5 |  Loss: 113.92850494384766\n",
            "Checkpoint Saved\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "819it [00:02, 343.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch: 6 |  Loss: 113.07160949707031\n",
            "Checkpoint Saved\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "819it [00:02, 292.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch: 7 |  Loss: 113.35860443115234\n",
            "Checkpoint Saved\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "819it [00:02, 339.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Epoch: 8 |  Loss: 112.86277770996094\n",
            "Checkpoint Saved\n",
            "\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [00:01, 341.92it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-8cfdd70e811d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Starting the main function ----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-90-abdd130ff4ea>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m#INDICATOR VARIABLE TO RESUME TRAINING OR START AFRESH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mtrain_val_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-08b75579912e>\u001b[0m in \u001b[0;36mtrain_val_test\u001b[0;34m(train_loader, test_loader, model, optimizer, n_epoch, resume)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#CHECKPOINT CREATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-d9a4c3b8b1c8>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, optimizer, epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RecordFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir history"
      ],
      "metadata": {
        "id": "7dF6M1t_JTk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir checkpoint"
      ],
      "metadata": {
        "id": "_MvmZ74jJfnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([0., 0., 1., 0., 0., 1., 1., 1., 0., 1.])\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "62IFuDVSMs2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baaede2d-7960-43c8-edfe-cfe937e40618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W3Y25q5IUQIM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}