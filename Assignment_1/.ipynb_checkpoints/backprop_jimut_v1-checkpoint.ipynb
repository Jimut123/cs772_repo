{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhTuMRktCX0F",
    "outputId": "035ec92b-0ca3-4253-ac5b-29b1ab59aab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-29 08:41:13--  https://jimut123.github.io/courses/vision/assets/sonar.csv\n",
      "Resolving jimut123.github.io (jimut123.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
      "Connecting to jimut123.github.io (jimut123.github.io)|185.199.108.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87776 (86K) [text/csv]\n",
      "Saving to: ‘sonar.csv.1’\n",
      "\n",
      "\r",
      "sonar.csv.1           0%[                    ]       0  --.-KB/s               \r",
      "sonar.csv.1         100%[===================>]  85.72K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-01-29 08:41:13 (6.20 MB/s) - ‘sonar.csv.1’ saved [87776/87776]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget \"https://jimut123.github.io/courses/vision/assets/sonar.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYVQuxgK6bhc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ss9_I8QaHVjX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sonar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgZEh41gHoQg",
    "outputId": "4041cd6b-279c-49a2-c5c2-56ecd09ae05f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 61)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3FTvLccHqH3"
   },
   "outputs": [],
   "source": [
    "X = df.to_numpy()[:,:60]\n",
    "Y = df.to_numpy()[:,60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e_0vFcaDIGzQ",
    "outputId": "b69f2f85-569e-451d-d96c-5802790943ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 60)\n",
      "(207, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "biMkyoWCcXAn"
   },
   "outputs": [],
   "source": [
    " def get__number_from_pal(str_num):\n",
    "    return np.fromiter((int(bit) for bit in str_num), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X11xpB-UcW9w"
   },
   "outputs": [],
   "source": [
    "# Generating palindrome data\n",
    "\n",
    "def is_pal(X):\n",
    "    return X == X[::-1]\n",
    "\n",
    "def generate_10_bit_binary_numbers():\n",
    "    binary_numbers = []\n",
    "\n",
    "    for i in range(2**10):\n",
    "        binary_str = format(i, '010b')\n",
    "        binary_numbers.append(binary_str)\n",
    "\n",
    "    return binary_numbers\n",
    "\n",
    "\n",
    "# Generate and store all 10-bit binary numbers\n",
    "binary_numbers_list = generate_10_bit_binary_numbers()\n",
    "\n",
    "\n",
    "Y_VALUES = []\n",
    "X_VALUES = []\n",
    "\n",
    "# Print and/or use the generated binary numbers as needed\n",
    "for binary_number in binary_numbers_list:\n",
    "    #print(binary_number)\n",
    "    if is_pal(binary_number) == True:\n",
    "        X_VALUES.append(get__number_from_pal(binary_number))\n",
    "        Y_VALUES.append(1)\n",
    "    else:\n",
    "        X_VALUES.append(get__number_from_pal(binary_number))\n",
    "        Y_VALUES.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gsQCfGkc9g_",
    "outputId": "2887d026-8916-4791-8d7c-83fea77488b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X =  (1024, 10)\n",
      "Y =  (1024,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X_VALUES)\n",
    "Y = np.array(Y_VALUES)\n",
    "print(\"X = \",X.shape)\n",
    "print(\"Y = \",Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FP2t7ehwccAR"
   },
   "outputs": [],
   "source": [
    "Y = Y.reshape(1024,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMqXR0Y3fLsw",
    "outputId": "1ee186a4-cb6b-4d44-cb20-e57fc9babab5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOXI6bhXcb9Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwiWlz516hZc"
   },
   "outputs": [],
   "source": [
    "# prompt: generate a blank class definition for a MLP in numpy\n",
    "\n",
    "class MLP:\n",
    "  def __init__(self, input, hidden):\n",
    "    self.w1 = np.random.rand(input, hidden)\n",
    "    # self.w1 = np.random.rand(10, hidden)\n",
    "    self.w2 = np.random.rand(hidden, 1)\n",
    "\n",
    "    self.hidden = hidden\n",
    "    self.input = input\n",
    "\n",
    "  def relu(self, x):\n",
    "    return np.maximum(x,0)\n",
    "\n",
    "  def relu_prime(self,x):\n",
    "    if x>0:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "  def sigmoid(self,x):\n",
    "    # return 1 / (1 + np.exp(-x))\n",
    "    return np.exp(-np.logaddexp(0, -x))\n",
    "\n",
    "\n",
    "  def sigmoid_prime(self,x):\n",
    "    z = self.sigmoid(x)\n",
    "    return z*(1-z)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # forward\n",
    "    z1 = self.w1.T @ x\n",
    "    a1 = self.relu(z1)\n",
    "\n",
    "    z2 = self.w2.T @ a1\n",
    "    a2 = self.sigmoid(z2)\n",
    "\n",
    "    return a2\n",
    "\n",
    "  def forward_backward(self, x, y, lr):\n",
    "\n",
    "    # forward\n",
    "    z1 = self.w1.T @ x\n",
    "    a1 = self.relu(z1)\n",
    "\n",
    "    z2 = self.w2.T @ a1\n",
    "    a2 = self.sigmoid(z2)\n",
    "\n",
    "    # backprop\n",
    "    self.dw1 = np.zeros_like(self.w1)\n",
    "    self.dw2 = np.zeros_like(self.w2)\n",
    "\n",
    "    L = -y*np.log(a2 + 1e-6) - (1-y)*np.log(1-a2 + 1e-6)\n",
    "    # da2 = -y/a2 + (1-y)/(1-a2)\n",
    "\n",
    "    for i in range(self.hidden):\n",
    "      self.dw2[i,0] = (-y[0,0]*(1-a2[0,0]) + (1- y[0,0])*a2[0,0]) * a1[i,0]\n",
    "      #self.dw2[i,0] = da2[0,0] * self.sigmoid_prime(z2[0,0]) * a1[i,0]\n",
    "\n",
    "    for i in range(self.input):\n",
    "      for j in range(self.hidden):\n",
    "        # self.dw1[i,0] = da2[0,0] * self.sigmoid_prime(z2[0,0]) * self.w2[j,0] * self.relu_prime(z1[j,0]) * x[i,0]\n",
    "        self.dw1[i,j] = (-y[0,0]*(1-a2[0,0]) + (1- y[0,0])*a2[0,0])  * self.w2[j,0] * self.relu_prime(z1[j,0]) * x[i,0]\n",
    "\n",
    "    # update\n",
    "    self.w1 = self.w1 - lr*self.dw1\n",
    "    self.w2 = self.w2 - lr*self.dw2\n",
    "\n",
    "    # print (np.linalg.norm(self.dw1))\n",
    "\n",
    "    return a2 , L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqP_ehkYI8VQ"
   },
   "outputs": [],
   "source": [
    "net = MLP(10, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04C8wiWYETrR"
   },
   "outputs": [],
   "source": [
    "# eval\n",
    "def inference():\n",
    "  print ('inference')\n",
    "  correct = 0\n",
    "\n",
    "  for i in range(len(X)):\n",
    "    x = X[i:i+1,:].T\n",
    "    y = Y[i,0]\n",
    "\n",
    "    y_pred = net.forward(x)\n",
    "\n",
    "    y_pred = y_pred[0,0]\n",
    "\n",
    "    # print (y_pred)\n",
    "\n",
    "    if y_pred < 0.5:\n",
    "      y_pred = 0\n",
    "    else:\n",
    "      y_pred = 1\n",
    "\n",
    "    if (y_pred == y):\n",
    "      correct +=1\n",
    "\n",
    "  print (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2BtKRooINiV",
    "outputId": "ed89948c-65f6-4aad-faef-b7d221ec0240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  loss:  [[363.05137166]]\n",
      "====\n",
      "inference\n",
      "984\n",
      "1  loss:  [[184.69852411]]\n",
      "====\n",
      "2  loss:  [[180.82583819]]\n",
      "====\n",
      "3  loss:  [[178.50792727]]\n",
      "====\n",
      "4  loss:  [[176.99807009]]\n",
      "====\n",
      "5  loss:  [[175.94539383]]\n",
      "====\n",
      "6  loss:  [[175.16655566]]\n",
      "====\n",
      "7  loss:  [[174.55894309]]\n",
      "====\n",
      "8  loss:  [[174.06015392]]\n",
      "====\n",
      "9  loss:  [[173.63809128]]\n",
      "====\n",
      "10  loss:  [[173.26998097]]\n",
      "====\n",
      "11  loss:  [[172.93909907]]\n",
      "====\n",
      "12  loss:  [[172.63695211]]\n",
      "====\n",
      "13  loss:  [[172.35786732]]\n",
      "====\n",
      "14  loss:  [[172.10202928]]\n",
      "====\n",
      "15  loss:  [[171.85885819]]\n",
      "====\n",
      "16  loss:  [[171.62965118]]\n",
      "====\n",
      "17  loss:  [[171.41299091]]\n",
      "====\n",
      "18  loss:  [[171.20813532]]\n",
      "====\n",
      "19  loss:  [[171.01291191]]\n",
      "====\n",
      "20  loss:  [[170.82725897]]\n",
      "====\n",
      "inference\n",
      "797\n",
      "21  loss:  [[170.64796308]]\n",
      "====\n",
      "22  loss:  [[170.47530098]]\n",
      "====\n",
      "23  loss:  [[170.31098504]]\n",
      "====\n",
      "24  loss:  [[170.15430615]]\n",
      "====\n",
      "25  loss:  [[170.00465276]]\n",
      "====\n",
      "26  loss:  [[169.86138267]]\n",
      "====\n",
      "27  loss:  [[169.72349803]]\n",
      "====\n",
      "28  loss:  [[169.59051631]]\n",
      "====\n",
      "29  loss:  [[169.46318332]]\n",
      "====\n",
      "30  loss:  [[169.33872817]]\n",
      "====\n",
      "31  loss:  [[169.21798185]]\n",
      "====\n",
      "32  loss:  [[169.10043136]]\n",
      "====\n",
      "33  loss:  [[168.98643567]]\n",
      "====\n",
      "34  loss:  [[168.87482442]]\n",
      "====\n",
      "35  loss:  [[168.76607979]]\n",
      "====\n",
      "36  loss:  [[168.6609779]]\n",
      "====\n",
      "37  loss:  [[168.55716092]]\n",
      "====\n",
      "38  loss:  [[168.45651415]]\n",
      "====\n",
      "39  loss:  [[168.3580009]]\n",
      "====\n",
      "40  loss:  [[168.26105562]]\n",
      "====\n",
      "inference\n",
      "790\n",
      "41  loss:  [[168.16264312]]\n",
      "====\n",
      "42  loss:  [[168.06441717]]\n",
      "====\n",
      "43  loss:  [[167.96736594]]\n",
      "====\n",
      "44  loss:  [[167.87101609]]\n",
      "====\n",
      "45  loss:  [[167.7755405]]\n",
      "====\n",
      "46  loss:  [[167.68218356]]\n",
      "====\n",
      "47  loss:  [[167.58830746]]\n",
      "====\n",
      "48  loss:  [[167.49271877]]\n",
      "====\n",
      "49  loss:  [[167.39818106]]\n",
      "====\n",
      "50  loss:  [[167.30525964]]\n",
      "====\n",
      "51  loss:  [[167.21353702]]\n",
      "====\n",
      "52  loss:  [[167.11696051]]\n",
      "====\n",
      "53  loss:  [[167.0199734]]\n",
      "====\n",
      "54  loss:  [[166.92291024]]\n",
      "====\n",
      "55  loss:  [[166.82619582]]\n",
      "====\n",
      "56  loss:  [[166.72868614]]\n",
      "====\n",
      "57  loss:  [[166.62703388]]\n",
      "====\n",
      "58  loss:  [[166.52310158]]\n",
      "====\n",
      "59  loss:  [[166.41507191]]\n",
      "====\n",
      "60  loss:  [[166.30724535]]\n",
      "====\n",
      "inference\n",
      "832\n",
      "61  loss:  [[166.19365079]]\n",
      "====\n",
      "62  loss:  [[166.07730355]]\n",
      "====\n",
      "63  loss:  [[165.95515219]]\n",
      "====\n",
      "64  loss:  [[165.83060505]]\n",
      "====\n",
      "65  loss:  [[165.69251813]]\n",
      "====\n",
      "66  loss:  [[165.53789448]]\n",
      "====\n",
      "67  loss:  [[165.3693471]]\n",
      "====\n",
      "68  loss:  [[165.19478267]]\n",
      "====\n",
      "69  loss:  [[164.99354377]]\n",
      "====\n",
      "70  loss:  [[164.77506192]]\n",
      "====\n",
      "71  loss:  [[164.54329681]]\n",
      "====\n",
      "72  loss:  [[164.28404888]]\n",
      "====\n",
      "73  loss:  [[163.99689845]]\n",
      "====\n",
      "74  loss:  [[163.67090324]]\n",
      "====\n",
      "75  loss:  [[163.27900833]]\n",
      "====\n",
      "76  loss:  [[162.8594629]]\n",
      "====\n",
      "77  loss:  [[162.41051074]]\n",
      "====\n",
      "78  loss:  [[161.92764805]]\n",
      "====\n",
      "79  loss:  [[161.39944531]]\n",
      "====\n",
      "80  loss:  [[160.71901589]]\n",
      "====\n",
      "inference\n",
      "931\n",
      "81  loss:  [[160.01169882]]\n",
      "====\n",
      "82  loss:  [[159.21482309]]\n",
      "====\n",
      "83  loss:  [[158.24003845]]\n",
      "====\n",
      "84  loss:  [[157.08000504]]\n",
      "====\n",
      "85  loss:  [[155.85996359]]\n",
      "====\n",
      "86  loss:  [[154.24450945]]\n",
      "====\n",
      "87  loss:  [[152.30822833]]\n",
      "====\n",
      "88  loss:  [[150.00486616]]\n",
      "====\n",
      "89  loss:  [[146.80426465]]\n",
      "====\n",
      "90  loss:  [[143.41102636]]\n",
      "====\n",
      "91  loss:  [[141.15488789]]\n",
      "====\n",
      "92  loss:  [[139.24511159]]\n",
      "====\n",
      "93  loss:  [[136.81377541]]\n",
      "====\n",
      "94  loss:  [[134.73566835]]\n",
      "====\n",
      "95  loss:  [[132.70067241]]\n",
      "====\n",
      "96  loss:  [[130.17274439]]\n",
      "====\n",
      "97  loss:  [[127.78649381]]\n",
      "====\n",
      "98  loss:  [[125.41078416]]\n",
      "====\n",
      "99  loss:  [[122.20968278]]\n",
      "====\n",
      "100  loss:  [[119.95367894]]\n",
      "====\n",
      "inference\n",
      "993\n",
      "101  loss:  [[116.83636747]]\n",
      "====\n",
      "102  loss:  [[113.78879877]]\n",
      "====\n",
      "103  loss:  [[110.01356408]]\n",
      "====\n",
      "104  loss:  [[105.69383998]]\n",
      "====\n",
      "105  loss:  [[101.37494418]]\n",
      "====\n",
      "106  loss:  [[97.01351034]]\n",
      "====\n",
      "107  loss:  [[93.20709008]]\n",
      "====\n",
      "108  loss:  [[89.99168646]]\n",
      "====\n",
      "109  loss:  [[87.36747255]]\n",
      "====\n",
      "110  loss:  [[83.91552262]]\n",
      "====\n",
      "111  loss:  [[80.60542633]]\n",
      "====\n",
      "112  loss:  [[77.80923826]]\n",
      "====\n",
      "113  loss:  [[74.73065149]]\n",
      "====\n",
      "114  loss:  [[72.16999068]]\n",
      "====\n",
      "115  loss:  [[68.77540222]]\n",
      "====\n",
      "116  loss:  [[65.79942463]]\n",
      "====\n",
      "117  loss:  [[63.27743112]]\n",
      "====\n",
      "118  loss:  [[60.2101963]]\n",
      "====\n",
      "119  loss:  [[57.46290576]]\n",
      "====\n",
      "120  loss:  [[54.37230675]]\n",
      "====\n",
      "inference\n",
      "1017\n",
      "121  loss:  [[51.76940463]]\n",
      "====\n",
      "122  loss:  [[49.3445236]]\n",
      "====\n",
      "123  loss:  [[46.55562513]]\n",
      "====\n",
      "124  loss:  [[44.08653229]]\n",
      "====\n",
      "125  loss:  [[41.67669219]]\n",
      "====\n",
      "126  loss:  [[39.56625794]]\n",
      "====\n",
      "127  loss:  [[37.91114875]]\n",
      "====\n",
      "128  loss:  [[35.47510918]]\n",
      "====\n",
      "129  loss:  [[33.54522692]]\n",
      "====\n",
      "130  loss:  [[32.15147994]]\n",
      "====\n",
      "131  loss:  [[30.64882297]]\n",
      "====\n",
      "132  loss:  [[28.98515945]]\n",
      "====\n",
      "133  loss:  [[27.65618373]]\n",
      "====\n",
      "134  loss:  [[26.5618859]]\n",
      "====\n",
      "135  loss:  [[25.35393508]]\n",
      "====\n",
      "136  loss:  [[24.37070068]]\n",
      "====\n",
      "137  loss:  [[23.40174019]]\n",
      "====\n",
      "138  loss:  [[22.45383858]]\n",
      "====\n",
      "139  loss:  [[21.61424468]]\n",
      "====\n",
      "140  loss:  [[20.78553384]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "141  loss:  [[20.02394402]]\n",
      "====\n",
      "142  loss:  [[19.29673857]]\n",
      "====\n",
      "143  loss:  [[18.69809943]]\n",
      "====\n",
      "144  loss:  [[17.99211794]]\n",
      "====\n",
      "145  loss:  [[17.44266394]]\n",
      "====\n",
      "146  loss:  [[16.8579123]]\n",
      "====\n",
      "147  loss:  [[16.33179879]]\n",
      "====\n",
      "148  loss:  [[15.84897946]]\n",
      "====\n",
      "149  loss:  [[15.37503275]]\n",
      "====\n",
      "150  loss:  [[14.95239742]]\n",
      "====\n",
      "151  loss:  [[14.50366306]]\n",
      "====\n",
      "152  loss:  [[14.09999806]]\n",
      "====\n",
      "153  loss:  [[13.73291512]]\n",
      "====\n",
      "154  loss:  [[13.4059692]]\n",
      "====\n",
      "155  loss:  [[13.03624486]]\n",
      "====\n",
      "156  loss:  [[12.72517773]]\n",
      "====\n",
      "157  loss:  [[12.41061425]]\n",
      "====\n",
      "158  loss:  [[12.13162579]]\n",
      "====\n",
      "159  loss:  [[11.83473847]]\n",
      "====\n",
      "160  loss:  [[11.58484572]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "161  loss:  [[11.30722682]]\n",
      "====\n",
      "162  loss:  [[11.04606027]]\n",
      "====\n",
      "163  loss:  [[10.82686997]]\n",
      "====\n",
      "164  loss:  [[10.58096039]]\n",
      "====\n",
      "165  loss:  [[10.37713902]]\n",
      "====\n",
      "166  loss:  [[10.15560211]]\n",
      "====\n",
      "167  loss:  [[9.95965107]]\n",
      "====\n",
      "168  loss:  [[9.75912002]]\n",
      "====\n",
      "169  loss:  [[9.55686597]]\n",
      "====\n",
      "170  loss:  [[9.37324892]]\n",
      "====\n",
      "171  loss:  [[9.19367281]]\n",
      "====\n",
      "172  loss:  [[9.03999733]]\n",
      "====\n",
      "173  loss:  [[8.85442952]]\n",
      "====\n",
      "174  loss:  [[8.6995734]]\n",
      "====\n",
      "175  loss:  [[8.53490646]]\n",
      "====\n",
      "176  loss:  [[8.40125542]]\n",
      "====\n",
      "177  loss:  [[8.23792748]]\n",
      "====\n",
      "178  loss:  [[8.10817816]]\n",
      "====\n",
      "179  loss:  [[7.95364397]]\n",
      "====\n",
      "180  loss:  [[7.82382202]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "181  loss:  [[7.70037367]]\n",
      "====\n",
      "182  loss:  [[7.5663463]]\n",
      "====\n",
      "183  loss:  [[7.43507098]]\n",
      "====\n",
      "184  loss:  [[7.28928431]]\n",
      "====\n",
      "185  loss:  [[7.17168204]]\n",
      "====\n",
      "186  loss:  [[7.00954289]]\n",
      "====\n",
      "187  loss:  [[6.90918243]]\n",
      "====\n",
      "188  loss:  [[6.78523617]]\n",
      "====\n",
      "189  loss:  [[6.66054969]]\n",
      "====\n",
      "190  loss:  [[6.55168466]]\n",
      "====\n",
      "191  loss:  [[6.4512235]]\n",
      "====\n",
      "192  loss:  [[6.34849853]]\n",
      "====\n",
      "193  loss:  [[6.25453935]]\n",
      "====\n",
      "194  loss:  [[6.15870659]]\n",
      "====\n",
      "195  loss:  [[6.06873262]]\n",
      "====\n",
      "196  loss:  [[5.97412385]]\n",
      "====\n",
      "197  loss:  [[5.90255535]]\n",
      "====\n",
      "198  loss:  [[5.79709131]]\n",
      "====\n",
      "199  loss:  [[5.71773847]]\n",
      "====\n",
      "200  loss:  [[5.63512054]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "201  loss:  [[5.57268884]]\n",
      "====\n",
      "202  loss:  [[5.48559442]]\n",
      "====\n",
      "203  loss:  [[5.41236208]]\n",
      "====\n",
      "204  loss:  [[5.34258577]]\n",
      "====\n",
      "205  loss:  [[5.28450265]]\n",
      "====\n",
      "206  loss:  [[5.2431524]]\n",
      "====\n",
      "207  loss:  [[5.17013624]]\n",
      "====\n",
      "208  loss:  [[5.11865121]]\n",
      "====\n",
      "209  loss:  [[5.06546895]]\n",
      "====\n",
      "210  loss:  [[5.01204011]]\n",
      "====\n",
      "211  loss:  [[4.97308117]]\n",
      "====\n",
      "212  loss:  [[4.91682109]]\n",
      "====\n",
      "213  loss:  [[4.88096313]]\n",
      "====\n",
      "214  loss:  [[4.82297798]]\n",
      "====\n",
      "215  loss:  [[4.77398276]]\n",
      "====\n",
      "216  loss:  [[4.74755534]]\n",
      "====\n",
      "217  loss:  [[4.68832957]]\n",
      "====\n",
      "218  loss:  [[4.64069548]]\n",
      "====\n",
      "219  loss:  [[4.61080115]]\n",
      "====\n",
      "220  loss:  [[4.57091788]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "221  loss:  [[4.52701166]]\n",
      "====\n",
      "222  loss:  [[4.49515215]]\n",
      "====\n",
      "223  loss:  [[4.44494238]]\n",
      "====\n",
      "224  loss:  [[4.39843743]]\n",
      "====\n",
      "225  loss:  [[4.37668551]]\n",
      "====\n",
      "226  loss:  [[4.33560297]]\n",
      "====\n",
      "227  loss:  [[4.30096482]]\n",
      "====\n",
      "228  loss:  [[4.26416578]]\n",
      "====\n",
      "229  loss:  [[4.22773137]]\n",
      "====\n",
      "230  loss:  [[4.19707409]]\n",
      "====\n",
      "231  loss:  [[4.15951519]]\n",
      "====\n",
      "232  loss:  [[4.12903999]]\n",
      "====\n",
      "233  loss:  [[4.08740469]]\n",
      "====\n",
      "234  loss:  [[4.05814017]]\n",
      "====\n",
      "235  loss:  [[4.02436218]]\n",
      "====\n",
      "236  loss:  [[3.99302493]]\n",
      "====\n",
      "237  loss:  [[3.96302769]]\n",
      "====\n",
      "238  loss:  [[3.93103605]]\n",
      "====\n",
      "239  loss:  [[3.89700652]]\n",
      "====\n",
      "240  loss:  [[3.87696234]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "241  loss:  [[3.84128747]]\n",
      "====\n",
      "242  loss:  [[3.81336184]]\n",
      "====\n",
      "243  loss:  [[3.78264379]]\n",
      "====\n",
      "244  loss:  [[3.74787122]]\n",
      "====\n",
      "245  loss:  [[3.74521547]]\n",
      "====\n",
      "246  loss:  [[3.69739667]]\n",
      "====\n",
      "247  loss:  [[3.67594716]]\n",
      "====\n",
      "248  loss:  [[3.65157395]]\n",
      "====\n",
      "249  loss:  [[3.62430952]]\n",
      "====\n",
      "250  loss:  [[3.60684155]]\n",
      "====\n",
      "251  loss:  [[3.56562303]]\n",
      "====\n",
      "252  loss:  [[3.54408556]]\n",
      "====\n",
      "253  loss:  [[3.52998558]]\n",
      "====\n",
      "254  loss:  [[3.50581275]]\n",
      "====\n",
      "255  loss:  [[3.47604952]]\n",
      "====\n",
      "256  loss:  [[3.45417046]]\n",
      "====\n",
      "257  loss:  [[3.42829248]]\n",
      "====\n",
      "258  loss:  [[3.41152435]]\n",
      "====\n",
      "259  loss:  [[3.38464301]]\n",
      "====\n",
      "260  loss:  [[3.36779808]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "261  loss:  [[3.34152141]]\n",
      "====\n",
      "262  loss:  [[3.31902633]]\n",
      "====\n",
      "263  loss:  [[3.30235203]]\n",
      "====\n",
      "264  loss:  [[3.27840771]]\n",
      "====\n",
      "265  loss:  [[3.25711677]]\n",
      "====\n",
      "266  loss:  [[3.23184252]]\n",
      "====\n",
      "267  loss:  [[3.22066603]]\n",
      "====\n",
      "268  loss:  [[3.18671479]]\n",
      "====\n",
      "269  loss:  [[3.17917382]]\n",
      "====\n",
      "270  loss:  [[3.15169259]]\n",
      "====\n",
      "271  loss:  [[3.14248716]]\n",
      "====\n",
      "272  loss:  [[3.10676111]]\n",
      "====\n",
      "273  loss:  [[3.10694495]]\n",
      "====\n",
      "274  loss:  [[3.08093411]]\n",
      "====\n",
      "275  loss:  [[3.07085587]]\n",
      "====\n",
      "276  loss:  [[3.04027745]]\n",
      "====\n",
      "277  loss:  [[3.03119755]]\n",
      "====\n",
      "278  loss:  [[3.01054505]]\n",
      "====\n",
      "279  loss:  [[2.98437385]]\n",
      "====\n",
      "280  loss:  [[2.97646999]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "281  loss:  [[2.96177199]]\n",
      "====\n",
      "282  loss:  [[2.94584163]]\n",
      "====\n",
      "283  loss:  [[2.92484788]]\n",
      "====\n",
      "284  loss:  [[2.90852124]]\n",
      "====\n",
      "285  loss:  [[2.89894613]]\n",
      "====\n",
      "286  loss:  [[2.87415543]]\n",
      "====\n",
      "287  loss:  [[2.86309642]]\n",
      "====\n",
      "288  loss:  [[2.8424882]]\n",
      "====\n",
      "289  loss:  [[2.84128956]]\n",
      "====\n",
      "290  loss:  [[2.81639446]]\n",
      "====\n",
      "291  loss:  [[2.80281878]]\n",
      "====\n",
      "292  loss:  [[2.79457134]]\n",
      "====\n",
      "293  loss:  [[2.7723688]]\n",
      "====\n",
      "294  loss:  [[2.75636327]]\n",
      "====\n",
      "295  loss:  [[2.74416782]]\n",
      "====\n",
      "296  loss:  [[2.72977094]]\n",
      "====\n",
      "297  loss:  [[2.7226772]]\n",
      "====\n",
      "298  loss:  [[2.70217998]]\n",
      "====\n",
      "299  loss:  [[2.69281003]]\n",
      "====\n",
      "300  loss:  [[2.67446366]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "301  loss:  [[2.6667317]]\n",
      "====\n",
      "302  loss:  [[2.65383469]]\n",
      "====\n",
      "303  loss:  [[2.63418532]]\n",
      "====\n",
      "304  loss:  [[2.63254878]]\n",
      "====\n",
      "305  loss:  [[2.6139309]]\n",
      "====\n",
      "306  loss:  [[2.60247611]]\n",
      "====\n",
      "307  loss:  [[2.58800591]]\n",
      "====\n",
      "308  loss:  [[2.5784984]]\n",
      "====\n",
      "309  loss:  [[2.56305755]]\n",
      "====\n",
      "310  loss:  [[2.5466716]]\n",
      "====\n",
      "311  loss:  [[2.53772465]]\n",
      "====\n",
      "312  loss:  [[2.52904758]]\n",
      "====\n",
      "313  loss:  [[2.51378688]]\n",
      "====\n",
      "314  loss:  [[2.50584635]]\n",
      "====\n",
      "315  loss:  [[2.48833799]]\n",
      "====\n",
      "316  loss:  [[2.48130286]]\n",
      "====\n",
      "317  loss:  [[2.47066087]]\n",
      "====\n",
      "318  loss:  [[2.45800535]]\n",
      "====\n",
      "319  loss:  [[2.44861998]]\n",
      "====\n",
      "320  loss:  [[2.4317837]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "321  loss:  [[2.41981824]]\n",
      "====\n",
      "322  loss:  [[2.41856732]]\n",
      "====\n",
      "323  loss:  [[2.41022115]]\n",
      "====\n",
      "324  loss:  [[2.39574396]]\n",
      "====\n",
      "325  loss:  [[2.38595004]]\n",
      "====\n",
      "326  loss:  [[2.36851265]]\n",
      "====\n",
      "327  loss:  [[2.36428886]]\n",
      "====\n",
      "328  loss:  [[2.3556893]]\n",
      "====\n",
      "329  loss:  [[2.34981216]]\n",
      "====\n",
      "330  loss:  [[2.33443396]]\n",
      "====\n",
      "331  loss:  [[2.3264347]]\n",
      "====\n",
      "332  loss:  [[2.32151831]]\n",
      "====\n",
      "333  loss:  [[2.30195885]]\n",
      "====\n",
      "334  loss:  [[2.29845657]]\n",
      "====\n",
      "335  loss:  [[2.29633693]]\n",
      "====\n",
      "336  loss:  [[2.28478417]]\n",
      "====\n",
      "337  loss:  [[2.27069379]]\n",
      "====\n",
      "338  loss:  [[2.26069705]]\n",
      "====\n",
      "339  loss:  [[2.25419962]]\n",
      "====\n",
      "340  loss:  [[2.25176175]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "341  loss:  [[2.23943995]]\n",
      "====\n",
      "342  loss:  [[2.22826997]]\n",
      "====\n",
      "343  loss:  [[2.22299401]]\n",
      "====\n",
      "344  loss:  [[2.20695667]]\n",
      "====\n",
      "345  loss:  [[2.20554594]]\n",
      "====\n",
      "346  loss:  [[2.19559148]]\n",
      "====\n",
      "347  loss:  [[2.18801758]]\n",
      "====\n",
      "348  loss:  [[2.16515011]]\n",
      "====\n",
      "349  loss:  [[2.1588685]]\n",
      "====\n",
      "350  loss:  [[2.16322701]]\n",
      "====\n",
      "351  loss:  [[2.15285013]]\n",
      "====\n",
      "352  loss:  [[2.13743248]]\n",
      "====\n",
      "353  loss:  [[2.13711401]]\n",
      "====\n",
      "354  loss:  [[2.12907123]]\n",
      "====\n",
      "355  loss:  [[2.11614198]]\n",
      "====\n",
      "356  loss:  [[2.10951932]]\n",
      "====\n",
      "357  loss:  [[2.09431341]]\n",
      "====\n",
      "358  loss:  [[2.09939278]]\n",
      "====\n",
      "359  loss:  [[2.08546958]]\n",
      "====\n",
      "360  loss:  [[2.0857396]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "361  loss:  [[2.07970812]]\n",
      "====\n",
      "362  loss:  [[2.05713947]]\n",
      "====\n",
      "363  loss:  [[2.06612332]]\n",
      "====\n",
      "364  loss:  [[2.0548226]]\n",
      "====\n",
      "365  loss:  [[2.05271511]]\n",
      "====\n",
      "366  loss:  [[2.04385838]]\n",
      "====\n",
      "367  loss:  [[2.035728]]\n",
      "====\n",
      "368  loss:  [[2.03232399]]\n",
      "====\n",
      "369  loss:  [[2.02192667]]\n",
      "====\n",
      "370  loss:  [[2.01855046]]\n",
      "====\n",
      "371  loss:  [[2.01639347]]\n",
      "====\n",
      "372  loss:  [[1.99203826]]\n",
      "====\n",
      "373  loss:  [[2.01150223]]\n",
      "====\n",
      "374  loss:  [[1.98945166]]\n",
      "====\n",
      "375  loss:  [[1.98870752]]\n",
      "====\n",
      "376  loss:  [[1.9868737]]\n",
      "====\n",
      "377  loss:  [[1.98107278]]\n",
      "====\n",
      "378  loss:  [[1.9701549]]\n",
      "====\n",
      "379  loss:  [[1.96709352]]\n",
      "====\n",
      "380  loss:  [[1.96419765]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "381  loss:  [[1.95322289]]\n",
      "====\n",
      "382  loss:  [[1.94278219]]\n",
      "====\n",
      "383  loss:  [[1.93691402]]\n",
      "====\n",
      "384  loss:  [[1.94703633]]\n",
      "====\n",
      "385  loss:  [[1.93703248]]\n",
      "====\n",
      "386  loss:  [[1.92779591]]\n",
      "====\n",
      "387  loss:  [[1.92131041]]\n",
      "====\n",
      "388  loss:  [[1.91106251]]\n",
      "====\n",
      "389  loss:  [[1.91101267]]\n",
      "====\n",
      "390  loss:  [[1.90829392]]\n",
      "====\n",
      "391  loss:  [[1.90263741]]\n",
      "====\n",
      "392  loss:  [[1.88931983]]\n",
      "====\n",
      "393  loss:  [[1.8844394]]\n",
      "====\n",
      "394  loss:  [[1.88656395]]\n",
      "====\n",
      "395  loss:  [[1.88643053]]\n",
      "====\n",
      "396  loss:  [[1.87500715]]\n",
      "====\n",
      "397  loss:  [[1.86109878]]\n",
      "====\n",
      "398  loss:  [[1.8583025]]\n",
      "====\n",
      "399  loss:  [[1.86020643]]\n",
      "====\n",
      "400  loss:  [[1.84847975]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "401  loss:  [[1.84365215]]\n",
      "====\n",
      "402  loss:  [[1.84174929]]\n",
      "====\n",
      "403  loss:  [[1.83191678]]\n",
      "====\n",
      "404  loss:  [[1.83597825]]\n",
      "====\n",
      "405  loss:  [[1.82289499]]\n",
      "====\n",
      "406  loss:  [[1.82628892]]\n",
      "====\n",
      "407  loss:  [[1.81218295]]\n",
      "====\n",
      "408  loss:  [[1.80609998]]\n",
      "====\n",
      "409  loss:  [[1.81057931]]\n",
      "====\n",
      "410  loss:  [[1.79870352]]\n",
      "====\n",
      "411  loss:  [[1.79600843]]\n",
      "====\n",
      "412  loss:  [[1.78031183]]\n",
      "====\n",
      "413  loss:  [[1.79194708]]\n",
      "====\n",
      "414  loss:  [[1.78202966]]\n",
      "====\n",
      "415  loss:  [[1.77446996]]\n",
      "====\n",
      "416  loss:  [[1.77252099]]\n",
      "====\n",
      "417  loss:  [[1.764288]]\n",
      "====\n",
      "418  loss:  [[1.76742795]]\n",
      "====\n",
      "419  loss:  [[1.75148058]]\n",
      "====\n",
      "420  loss:  [[1.75007838]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "421  loss:  [[1.75308798]]\n",
      "====\n",
      "422  loss:  [[1.74005251]]\n",
      "====\n",
      "423  loss:  [[1.741227]]\n",
      "====\n",
      "424  loss:  [[1.74095169]]\n",
      "====\n",
      "425  loss:  [[1.72908551]]\n",
      "====\n",
      "426  loss:  [[1.72971339]]\n",
      "====\n",
      "427  loss:  [[1.71581064]]\n",
      "====\n",
      "428  loss:  [[1.71609742]]\n",
      "====\n",
      "429  loss:  [[1.71407683]]\n",
      "====\n",
      "430  loss:  [[1.70722391]]\n",
      "====\n",
      "431  loss:  [[1.70892711]]\n",
      "====\n",
      "432  loss:  [[1.70145068]]\n",
      "====\n",
      "433  loss:  [[1.69505176]]\n",
      "====\n",
      "434  loss:  [[1.69275549]]\n",
      "====\n",
      "435  loss:  [[1.68714939]]\n",
      "====\n",
      "436  loss:  [[1.68058002]]\n",
      "====\n",
      "437  loss:  [[1.68245885]]\n",
      "====\n",
      "438  loss:  [[1.68025716]]\n",
      "====\n",
      "439  loss:  [[1.67253271]]\n",
      "====\n",
      "440  loss:  [[1.66813011]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "441  loss:  [[1.65553444]]\n",
      "====\n",
      "442  loss:  [[1.66586831]]\n",
      "====\n",
      "443  loss:  [[1.65726764]]\n",
      "====\n",
      "444  loss:  [[1.653885]]\n",
      "====\n",
      "445  loss:  [[1.65095402]]\n",
      "====\n",
      "446  loss:  [[1.64490202]]\n",
      "====\n",
      "447  loss:  [[1.63651176]]\n",
      "====\n",
      "448  loss:  [[1.63780344]]\n",
      "====\n",
      "449  loss:  [[1.63886825]]\n",
      "====\n",
      "450  loss:  [[1.62882497]]\n",
      "====\n",
      "451  loss:  [[1.62625803]]\n",
      "====\n",
      "452  loss:  [[1.62102953]]\n",
      "====\n",
      "453  loss:  [[1.62371515]]\n",
      "====\n",
      "454  loss:  [[1.61039165]]\n",
      "====\n",
      "455  loss:  [[1.6191502]]\n",
      "====\n",
      "456  loss:  [[1.61099562]]\n",
      "====\n",
      "457  loss:  [[1.60017382]]\n",
      "====\n",
      "458  loss:  [[1.60035004]]\n",
      "====\n",
      "459  loss:  [[1.60264759]]\n",
      "====\n",
      "460  loss:  [[1.59400965]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "461  loss:  [[1.59262788]]\n",
      "====\n",
      "462  loss:  [[1.58256602]]\n",
      "====\n",
      "463  loss:  [[1.58679219]]\n",
      "====\n",
      "464  loss:  [[1.58130688]]\n",
      "====\n",
      "465  loss:  [[1.5775436]]\n",
      "====\n",
      "466  loss:  [[1.57302787]]\n",
      "====\n",
      "467  loss:  [[1.56881357]]\n",
      "====\n",
      "468  loss:  [[1.57197289]]\n",
      "====\n",
      "469  loss:  [[1.56429852]]\n",
      "====\n",
      "470  loss:  [[1.55370425]]\n",
      "====\n",
      "471  loss:  [[1.56156398]]\n",
      "====\n",
      "472  loss:  [[1.55419524]]\n",
      "====\n",
      "473  loss:  [[1.54716433]]\n",
      "====\n",
      "474  loss:  [[1.54811687]]\n",
      "====\n",
      "475  loss:  [[1.54398149]]\n",
      "====\n",
      "476  loss:  [[1.5389547]]\n",
      "====\n",
      "477  loss:  [[1.53847719]]\n",
      "====\n",
      "478  loss:  [[1.52956355]]\n",
      "====\n",
      "479  loss:  [[1.53419232]]\n",
      "====\n",
      "480  loss:  [[1.52619212]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "481  loss:  [[1.53056944]]\n",
      "====\n",
      "482  loss:  [[1.51153686]]\n",
      "====\n",
      "483  loss:  [[1.52054597]]\n",
      "====\n",
      "484  loss:  [[1.52001828]]\n",
      "====\n",
      "485  loss:  [[1.51078624]]\n",
      "====\n",
      "486  loss:  [[1.50994838]]\n",
      "====\n",
      "487  loss:  [[1.50422622]]\n",
      "====\n",
      "488  loss:  [[1.50304203]]\n",
      "====\n",
      "489  loss:  [[1.49981817]]\n",
      "====\n",
      "490  loss:  [[1.49453074]]\n",
      "====\n",
      "491  loss:  [[1.49361668]]\n",
      "====\n",
      "492  loss:  [[1.49610575]]\n",
      "====\n",
      "493  loss:  [[1.48896516]]\n",
      "====\n",
      "494  loss:  [[1.48046249]]\n",
      "====\n",
      "495  loss:  [[1.48593967]]\n",
      "====\n",
      "496  loss:  [[1.48094399]]\n",
      "====\n",
      "497  loss:  [[1.47817423]]\n",
      "====\n",
      "498  loss:  [[1.47072398]]\n",
      "====\n",
      "499  loss:  [[1.47280003]]\n",
      "====\n",
      "500  loss:  [[1.47171146]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "501  loss:  [[1.46412656]]\n",
      "====\n",
      "502  loss:  [[1.463795]]\n",
      "====\n",
      "503  loss:  [[1.46165222]]\n",
      "====\n",
      "504  loss:  [[1.45720344]]\n",
      "====\n",
      "505  loss:  [[1.45524042]]\n",
      "====\n",
      "506  loss:  [[1.45060428]]\n",
      "====\n",
      "507  loss:  [[1.44998394]]\n",
      "====\n",
      "508  loss:  [[1.44690932]]\n",
      "====\n",
      "509  loss:  [[1.44420478]]\n",
      "====\n",
      "510  loss:  [[1.44134639]]\n",
      "====\n",
      "511  loss:  [[1.43825767]]\n",
      "====\n",
      "512  loss:  [[1.43602824]]\n",
      "====\n",
      "513  loss:  [[1.43378604]]\n",
      "====\n",
      "514  loss:  [[1.43195294]]\n",
      "====\n",
      "515  loss:  [[1.42767631]]\n",
      "====\n",
      "516  loss:  [[1.42335578]]\n",
      "====\n",
      "517  loss:  [[1.42889141]]\n",
      "====\n",
      "518  loss:  [[1.41757652]]\n",
      "====\n",
      "519  loss:  [[1.41967666]]\n",
      "====\n",
      "520  loss:  [[1.41613979]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "521  loss:  [[1.41541112]]\n",
      "====\n",
      "522  loss:  [[1.40922759]]\n",
      "====\n",
      "523  loss:  [[1.40548977]]\n",
      "====\n",
      "524  loss:  [[1.40707004]]\n",
      "====\n",
      "525  loss:  [[1.40496462]]\n",
      "====\n",
      "526  loss:  [[1.39969086]]\n",
      "====\n",
      "527  loss:  [[1.39912543]]\n",
      "====\n",
      "528  loss:  [[1.39594436]]\n",
      "====\n",
      "529  loss:  [[1.39290935]]\n",
      "====\n",
      "530  loss:  [[1.39272917]]\n",
      "====\n",
      "531  loss:  [[1.38876461]]\n",
      "====\n",
      "532  loss:  [[1.38617618]]\n",
      "====\n",
      "533  loss:  [[1.38618382]]\n",
      "====\n",
      "534  loss:  [[1.38150576]]\n",
      "====\n",
      "535  loss:  [[1.3803466]]\n",
      "====\n",
      "536  loss:  [[1.37517738]]\n",
      "====\n",
      "537  loss:  [[1.37859776]]\n",
      "====\n",
      "538  loss:  [[1.37352613]]\n",
      "====\n",
      "539  loss:  [[1.36963025]]\n",
      "====\n",
      "540  loss:  [[1.36608339]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "541  loss:  [[1.36753031]]\n",
      "====\n",
      "542  loss:  [[1.36179196]]\n",
      "====\n",
      "543  loss:  [[1.36111234]]\n",
      "====\n",
      "544  loss:  [[1.35707112]]\n",
      "====\n",
      "545  loss:  [[1.3543442]]\n",
      "====\n",
      "546  loss:  [[1.35419926]]\n",
      "====\n",
      "547  loss:  [[1.35493717]]\n",
      "====\n",
      "548  loss:  [[1.34449243]]\n",
      "====\n",
      "549  loss:  [[1.34356819]]\n",
      "====\n",
      "550  loss:  [[1.34782746]]\n",
      "====\n",
      "551  loss:  [[1.34219382]]\n",
      "====\n",
      "552  loss:  [[1.33845351]]\n",
      "====\n",
      "553  loss:  [[1.33880923]]\n",
      "====\n",
      "554  loss:  [[1.33349261]]\n",
      "====\n",
      "555  loss:  [[1.33338233]]\n",
      "====\n",
      "556  loss:  [[1.33027256]]\n",
      "====\n",
      "557  loss:  [[1.32719867]]\n",
      "====\n",
      "558  loss:  [[1.32923475]]\n",
      "====\n",
      "559  loss:  [[1.32274831]]\n",
      "====\n",
      "560  loss:  [[1.32084023]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "561  loss:  [[1.32056493]]\n",
      "====\n",
      "562  loss:  [[1.31791723]]\n",
      "====\n",
      "563  loss:  [[1.31679355]]\n",
      "====\n",
      "564  loss:  [[1.31066397]]\n",
      "====\n",
      "565  loss:  [[1.31248579]]\n",
      "====\n",
      "566  loss:  [[1.31048976]]\n",
      "====\n",
      "567  loss:  [[1.30740331]]\n",
      "====\n",
      "568  loss:  [[1.30467896]]\n",
      "====\n",
      "569  loss:  [[1.30176776]]\n",
      "====\n",
      "570  loss:  [[1.30202288]]\n",
      "====\n",
      "571  loss:  [[1.29945569]]\n",
      "====\n",
      "572  loss:  [[1.29786752]]\n",
      "====\n",
      "573  loss:  [[1.2938559]]\n",
      "====\n",
      "574  loss:  [[1.29269076]]\n",
      "====\n",
      "575  loss:  [[1.29422612]]\n",
      "====\n",
      "576  loss:  [[1.28823547]]\n",
      "====\n",
      "577  loss:  [[1.28584435]]\n",
      "====\n",
      "578  loss:  [[1.28782232]]\n",
      "====\n",
      "579  loss:  [[1.28407204]]\n",
      "====\n",
      "580  loss:  [[1.27918001]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "581  loss:  [[1.27992115]]\n",
      "====\n",
      "582  loss:  [[1.28125892]]\n",
      "====\n",
      "583  loss:  [[1.27501241]]\n",
      "====\n",
      "584  loss:  [[1.27155251]]\n",
      "====\n",
      "585  loss:  [[1.27414654]]\n",
      "====\n",
      "586  loss:  [[1.27006223]]\n",
      "====\n",
      "587  loss:  [[1.26834914]]\n",
      "====\n",
      "588  loss:  [[1.27034212]]\n",
      "====\n",
      "589  loss:  [[1.2626884]]\n",
      "====\n",
      "590  loss:  [[1.26479936]]\n",
      "====\n",
      "591  loss:  [[1.26172346]]\n",
      "====\n",
      "592  loss:  [[1.26058238]]\n",
      "====\n",
      "593  loss:  [[1.25681096]]\n",
      "====\n",
      "594  loss:  [[1.25738497]]\n",
      "====\n",
      "595  loss:  [[1.25467428]]\n",
      "====\n",
      "596  loss:  [[1.2530439]]\n",
      "====\n",
      "597  loss:  [[1.25141875]]\n",
      "====\n",
      "598  loss:  [[1.2530936]]\n",
      "====\n",
      "599  loss:  [[1.24285564]]\n",
      "====\n",
      "600  loss:  [[1.24928493]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "601  loss:  [[1.24533121]]\n",
      "====\n",
      "602  loss:  [[1.24260492]]\n",
      "====\n",
      "603  loss:  [[1.23836953]]\n",
      "====\n",
      "604  loss:  [[1.24432071]]\n",
      "====\n",
      "605  loss:  [[1.23601798]]\n",
      "====\n",
      "606  loss:  [[1.23810185]]\n",
      "====\n",
      "607  loss:  [[1.23538592]]\n",
      "====\n",
      "608  loss:  [[1.23198156]]\n",
      "====\n",
      "609  loss:  [[1.23202521]]\n",
      "====\n",
      "610  loss:  [[1.23246906]]\n",
      "====\n",
      "611  loss:  [[1.22628269]]\n",
      "====\n",
      "612  loss:  [[1.22752087]]\n",
      "====\n",
      "613  loss:  [[1.22572838]]\n",
      "====\n",
      "614  loss:  [[1.22516846]]\n",
      "====\n",
      "615  loss:  [[1.22208624]]\n",
      "====\n",
      "616  loss:  [[1.22341253]]\n",
      "====\n",
      "617  loss:  [[1.21686412]]\n",
      "====\n",
      "618  loss:  [[1.21933206]]\n",
      "====\n",
      "619  loss:  [[1.21763935]]\n",
      "====\n",
      "620  loss:  [[1.21342994]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "621  loss:  [[1.21290932]]\n",
      "====\n",
      "622  loss:  [[1.21512558]]\n",
      "====\n",
      "623  loss:  [[1.21021465]]\n",
      "====\n",
      "624  loss:  [[1.20795684]]\n",
      "====\n",
      "625  loss:  [[1.20811896]]\n",
      "====\n",
      "626  loss:  [[1.20845424]]\n",
      "====\n",
      "627  loss:  [[1.2029659]]\n",
      "====\n",
      "628  loss:  [[1.20492824]]\n",
      "====\n",
      "629  loss:  [[1.20392126]]\n",
      "====\n",
      "630  loss:  [[1.19858673]]\n",
      "====\n",
      "631  loss:  [[1.20083893]]\n",
      "====\n",
      "632  loss:  [[1.19793535]]\n",
      "====\n",
      "633  loss:  [[1.1964436]]\n",
      "====\n",
      "634  loss:  [[1.19499394]]\n",
      "====\n",
      "635  loss:  [[1.19387439]]\n",
      "====\n",
      "636  loss:  [[1.19373187]]\n",
      "====\n",
      "637  loss:  [[1.19265113]]\n",
      "====\n",
      "638  loss:  [[1.18844161]]\n",
      "====\n",
      "639  loss:  [[1.18835681]]\n",
      "====\n",
      "640  loss:  [[1.18910721]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "641  loss:  [[1.18595517]]\n",
      "====\n",
      "642  loss:  [[1.18533407]]\n",
      "====\n",
      "643  loss:  [[1.18294828]]\n",
      "====\n",
      "644  loss:  [[1.18329549]]\n",
      "====\n",
      "645  loss:  [[1.17850958]]\n",
      "====\n",
      "646  loss:  [[1.18263719]]\n",
      "====\n",
      "647  loss:  [[1.17581995]]\n",
      "====\n",
      "648  loss:  [[1.17711885]]\n",
      "====\n",
      "649  loss:  [[1.17599254]]\n",
      "====\n",
      "650  loss:  [[1.17397413]]\n",
      "====\n",
      "651  loss:  [[1.17277013]]\n",
      "====\n",
      "652  loss:  [[1.17221615]]\n",
      "====\n",
      "653  loss:  [[1.16934972]]\n",
      "====\n",
      "654  loss:  [[1.16788223]]\n",
      "====\n",
      "655  loss:  [[1.17019135]]\n",
      "====\n",
      "656  loss:  [[1.16575223]]\n",
      "====\n",
      "657  loss:  [[1.16255664]]\n",
      "====\n",
      "658  loss:  [[1.16553108]]\n",
      "====\n",
      "659  loss:  [[1.16359167]]\n",
      "====\n",
      "660  loss:  [[1.15997829]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "661  loss:  [[1.15846]]\n",
      "====\n",
      "662  loss:  [[1.16097426]]\n",
      "====\n",
      "663  loss:  [[1.1576145]]\n",
      "====\n",
      "664  loss:  [[1.15632238]]\n",
      "====\n",
      "665  loss:  [[1.15296327]]\n",
      "====\n",
      "666  loss:  [[1.15574153]]\n",
      "====\n",
      "667  loss:  [[1.15433565]]\n",
      "====\n",
      "668  loss:  [[1.1500878]]\n",
      "====\n",
      "669  loss:  [[1.14822309]]\n",
      "====\n",
      "670  loss:  [[1.15181864]]\n",
      "====\n",
      "671  loss:  [[1.14894127]]\n",
      "====\n",
      "672  loss:  [[1.14280765]]\n",
      "====\n",
      "673  loss:  [[1.14669623]]\n",
      "====\n",
      "674  loss:  [[1.14639798]]\n",
      "====\n",
      "675  loss:  [[1.1424574]]\n",
      "====\n",
      "676  loss:  [[1.14157724]]\n",
      "====\n",
      "677  loss:  [[1.14073706]]\n",
      "====\n",
      "678  loss:  [[1.13995592]]\n",
      "====\n",
      "679  loss:  [[1.13861467]]\n",
      "====\n",
      "680  loss:  [[1.13774235]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "681  loss:  [[1.13567813]]\n",
      "====\n",
      "682  loss:  [[1.1370462]]\n",
      "====\n",
      "683  loss:  [[1.13360729]]\n",
      "====\n",
      "684  loss:  [[1.13201545]]\n",
      "====\n",
      "685  loss:  [[1.13314133]]\n",
      "====\n",
      "686  loss:  [[1.13179797]]\n",
      "====\n",
      "687  loss:  [[1.12828566]]\n",
      "====\n",
      "688  loss:  [[1.12806912]]\n",
      "====\n",
      "689  loss:  [[1.12878579]]\n",
      "====\n",
      "690  loss:  [[1.12581534]]\n",
      "====\n",
      "691  loss:  [[1.12697287]]\n",
      "====\n",
      "692  loss:  [[1.12301563]]\n",
      "====\n",
      "693  loss:  [[1.1240333]]\n",
      "====\n",
      "694  loss:  [[1.1229088]]\n",
      "====\n",
      "695  loss:  [[1.12174711]]\n",
      "====\n",
      "696  loss:  [[1.11823451]]\n",
      "====\n",
      "697  loss:  [[1.1220819]]\n",
      "====\n",
      "698  loss:  [[1.11702331]]\n",
      "====\n",
      "699  loss:  [[1.11726828]]\n",
      "====\n",
      "700  loss:  [[1.11624557]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "701  loss:  [[1.11605905]]\n",
      "====\n",
      "702  loss:  [[1.11237927]]\n",
      "====\n",
      "703  loss:  [[1.11366366]]\n",
      "====\n",
      "704  loss:  [[1.11224838]]\n",
      "====\n",
      "705  loss:  [[1.11032317]]\n",
      "====\n",
      "706  loss:  [[1.11228674]]\n",
      "====\n",
      "707  loss:  [[1.10809168]]\n",
      "====\n",
      "708  loss:  [[1.10797404]]\n",
      "====\n",
      "709  loss:  [[1.10696006]]\n",
      "====\n",
      "710  loss:  [[1.10758852]]\n",
      "====\n",
      "711  loss:  [[1.10446886]]\n",
      "====\n",
      "712  loss:  [[1.10451501]]\n",
      "====\n",
      "713  loss:  [[1.10342952]]\n",
      "====\n",
      "714  loss:  [[1.10177006]]\n",
      "====\n",
      "715  loss:  [[1.1026382]]\n",
      "====\n",
      "716  loss:  [[1.09897074]]\n",
      "====\n",
      "717  loss:  [[1.10047726]]\n",
      "====\n",
      "718  loss:  [[1.09842598]]\n",
      "====\n",
      "719  loss:  [[1.09847257]]\n",
      "====\n",
      "720  loss:  [[1.09519276]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "721  loss:  [[1.09634756]]\n",
      "====\n",
      "722  loss:  [[1.09631445]]\n",
      "====\n",
      "723  loss:  [[1.09255381]]\n",
      "====\n",
      "724  loss:  [[1.09333028]]\n",
      "====\n",
      "725  loss:  [[1.09275228]]\n",
      "====\n",
      "726  loss:  [[1.09152653]]\n",
      "====\n",
      "727  loss:  [[1.09062731]]\n",
      "====\n",
      "728  loss:  [[1.08916182]]\n",
      "====\n",
      "729  loss:  [[1.08842135]]\n",
      "====\n",
      "730  loss:  [[1.08839539]]\n",
      "====\n",
      "731  loss:  [[1.08737]]\n",
      "====\n",
      "732  loss:  [[1.08435867]]\n",
      "====\n",
      "733  loss:  [[1.08646884]]\n",
      "====\n",
      "734  loss:  [[1.08423201]]\n",
      "====\n",
      "735  loss:  [[1.08398468]]\n",
      "====\n",
      "736  loss:  [[1.08189571]]\n",
      "====\n",
      "737  loss:  [[1.08079752]]\n",
      "====\n",
      "738  loss:  [[1.08206293]]\n",
      "====\n",
      "739  loss:  [[1.08087113]]\n",
      "====\n",
      "740  loss:  [[1.07712722]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "741  loss:  [[1.07902056]]\n",
      "====\n",
      "742  loss:  [[1.07945243]]\n",
      "====\n",
      "743  loss:  [[1.07582602]]\n",
      "====\n",
      "744  loss:  [[1.07420903]]\n",
      "====\n",
      "745  loss:  [[1.07734067]]\n",
      "====\n",
      "746  loss:  [[1.07296236]]\n",
      "====\n",
      "747  loss:  [[1.07311391]]\n",
      "====\n",
      "748  loss:  [[1.07372385]]\n",
      "====\n",
      "749  loss:  [[1.07133366]]\n",
      "====\n",
      "750  loss:  [[1.07076748]]\n",
      "====\n",
      "751  loss:  [[1.07096529]]\n",
      "====\n",
      "752  loss:  [[1.06824581]]\n",
      "====\n",
      "753  loss:  [[1.06842786]]\n",
      "====\n",
      "754  loss:  [[1.06820288]]\n",
      "====\n",
      "755  loss:  [[1.06741955]]\n",
      "====\n",
      "756  loss:  [[1.06474262]]\n",
      "====\n",
      "757  loss:  [[1.06734179]]\n",
      "====\n",
      "758  loss:  [[1.06400493]]\n",
      "====\n",
      "759  loss:  [[1.06427672]]\n",
      "====\n",
      "760  loss:  [[1.06235393]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "761  loss:  [[1.06174624]]\n",
      "====\n",
      "762  loss:  [[1.06247473]]\n",
      "====\n",
      "763  loss:  [[1.06082093]]\n",
      "====\n",
      "764  loss:  [[1.05830234]]\n",
      "====\n",
      "765  loss:  [[1.06062141]]\n",
      "====\n",
      "766  loss:  [[1.05869029]]\n",
      "====\n",
      "767  loss:  [[1.05702881]]\n",
      "====\n",
      "768  loss:  [[1.05670118]]\n",
      "====\n",
      "769  loss:  [[1.0575809]]\n",
      "====\n",
      "770  loss:  [[1.0551397]]\n",
      "====\n",
      "771  loss:  [[1.05429199]]\n",
      "====\n",
      "772  loss:  [[1.05409896]]\n",
      "====\n",
      "773  loss:  [[1.05353499]]\n",
      "====\n",
      "774  loss:  [[1.05158957]]\n",
      "====\n",
      "775  loss:  [[1.05373531]]\n",
      "====\n",
      "776  loss:  [[1.05066212]]\n",
      "====\n",
      "777  loss:  [[1.04883419]]\n",
      "====\n",
      "778  loss:  [[1.05117008]]\n",
      "====\n",
      "779  loss:  [[1.04907161]]\n",
      "====\n",
      "780  loss:  [[1.0462626]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "781  loss:  [[1.04918866]]\n",
      "====\n",
      "782  loss:  [[1.04761689]]\n",
      "====\n",
      "783  loss:  [[1.04395539]]\n",
      "====\n",
      "784  loss:  [[1.04691867]]\n",
      "====\n",
      "785  loss:  [[1.04537319]]\n",
      "====\n",
      "786  loss:  [[1.04387879]]\n",
      "====\n",
      "787  loss:  [[1.04259357]]\n",
      "====\n",
      "788  loss:  [[1.04376405]]\n",
      "====\n",
      "789  loss:  [[1.04167205]]\n",
      "====\n",
      "790  loss:  [[1.04143617]]\n",
      "====\n",
      "791  loss:  [[1.04037062]]\n",
      "====\n",
      "792  loss:  [[1.04031453]]\n",
      "====\n",
      "793  loss:  [[1.03912003]]\n",
      "====\n",
      "794  loss:  [[1.03914306]]\n",
      "====\n",
      "795  loss:  [[1.03685354]]\n",
      "====\n",
      "796  loss:  [[1.03819484]]\n",
      "====\n",
      "797  loss:  [[1.03554765]]\n",
      "====\n",
      "798  loss:  [[1.03689805]]\n",
      "====\n",
      "799  loss:  [[1.03513956]]\n",
      "====\n",
      "800  loss:  [[1.03385841]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "801  loss:  [[1.03517123]]\n",
      "====\n",
      "802  loss:  [[1.03296539]]\n",
      "====\n",
      "803  loss:  [[1.03304125]]\n",
      "====\n",
      "804  loss:  [[1.03194289]]\n",
      "====\n",
      "805  loss:  [[1.03256308]]\n",
      "====\n",
      "806  loss:  [[1.02961228]]\n",
      "====\n",
      "807  loss:  [[1.0300828]]\n",
      "====\n",
      "808  loss:  [[1.03136411]]\n",
      "====\n",
      "809  loss:  [[1.02795708]]\n",
      "====\n",
      "810  loss:  [[1.02856934]]\n",
      "====\n",
      "811  loss:  [[1.02760159]]\n",
      "====\n",
      "812  loss:  [[1.0267239]]\n",
      "====\n",
      "813  loss:  [[1.02640482]]\n",
      "====\n",
      "814  loss:  [[1.02752969]]\n",
      "====\n",
      "815  loss:  [[1.02306019]]\n",
      "====\n",
      "816  loss:  [[1.02540862]]\n",
      "====\n",
      "817  loss:  [[1.02466739]]\n",
      "====\n",
      "818  loss:  [[1.02304708]]\n",
      "====\n",
      "819  loss:  [[1.02199063]]\n",
      "====\n",
      "820  loss:  [[1.02208329]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "821  loss:  [[1.02229648]]\n",
      "====\n",
      "822  loss:  [[1.01976218]]\n",
      "====\n",
      "823  loss:  [[1.02130257]]\n",
      "====\n",
      "824  loss:  [[1.01959655]]\n",
      "====\n",
      "825  loss:  [[1.01914787]]\n",
      "====\n",
      "826  loss:  [[1.01868327]]\n",
      "====\n",
      "827  loss:  [[1.01852628]]\n",
      "====\n",
      "828  loss:  [[1.01671311]]\n",
      "====\n",
      "829  loss:  [[1.01768093]]\n",
      "====\n",
      "830  loss:  [[1.01528949]]\n",
      "====\n",
      "831  loss:  [[1.01568119]]\n",
      "====\n",
      "832  loss:  [[1.01507616]]\n",
      "====\n",
      "833  loss:  [[1.01451926]]\n",
      "====\n",
      "834  loss:  [[1.01413249]]\n",
      "====\n",
      "835  loss:  [[1.01341002]]\n",
      "====\n",
      "836  loss:  [[1.0134996]]\n",
      "====\n",
      "837  loss:  [[1.01159717]]\n",
      "====\n",
      "838  loss:  [[1.01112825]]\n",
      "====\n",
      "839  loss:  [[1.01220812]]\n",
      "====\n",
      "840  loss:  [[1.01010493]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "841  loss:  [[1.00880334]]\n",
      "====\n",
      "842  loss:  [[1.0107821]]\n",
      "====\n",
      "843  loss:  [[1.0083116]]\n",
      "====\n",
      "844  loss:  [[1.0083809]]\n",
      "====\n",
      "845  loss:  [[1.00719229]]\n",
      "====\n",
      "846  loss:  [[1.00867055]]\n",
      "====\n",
      "847  loss:  [[1.006782]]\n",
      "====\n",
      "848  loss:  [[1.00527296]]\n",
      "====\n",
      "849  loss:  [[1.00566787]]\n",
      "====\n",
      "850  loss:  [[1.00616733]]\n",
      "====\n",
      "851  loss:  [[1.00218753]]\n",
      "====\n",
      "852  loss:  [[1.0047048]]\n",
      "====\n",
      "853  loss:  [[1.00441104]]\n",
      "====\n",
      "854  loss:  [[1.0020677]]\n",
      "====\n",
      "855  loss:  [[1.00316191]]\n",
      "====\n",
      "856  loss:  [[1.00135226]]\n",
      "====\n",
      "857  loss:  [[1.00053865]]\n",
      "====\n",
      "858  loss:  [[1.00087849]]\n",
      "====\n",
      "859  loss:  [[1.0000808]]\n",
      "====\n",
      "860  loss:  [[1.00015104]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "861  loss:  [[0.99941108]]\n",
      "====\n",
      "862  loss:  [[0.99912792]]\n",
      "====\n",
      "863  loss:  [[0.9980812]]\n",
      "====\n",
      "864  loss:  [[0.99746034]]\n",
      "====\n",
      "865  loss:  [[0.99774593]]\n",
      "====\n",
      "866  loss:  [[0.99558445]]\n",
      "====\n",
      "867  loss:  [[0.99574335]]\n",
      "====\n",
      "868  loss:  [[0.99781993]]\n",
      "====\n",
      "869  loss:  [[0.99336435]]\n",
      "====\n",
      "870  loss:  [[0.99405253]]\n",
      "====\n",
      "871  loss:  [[0.99594261]]\n",
      "====\n",
      "872  loss:  [[0.99285799]]\n",
      "====\n",
      "873  loss:  [[0.99238514]]\n",
      "====\n",
      "874  loss:  [[0.99420288]]\n",
      "====\n",
      "875  loss:  [[0.991111]]\n",
      "====\n",
      "876  loss:  [[0.9909201]]\n",
      "====\n",
      "877  loss:  [[0.99195886]]\n",
      "====\n",
      "878  loss:  [[0.99166646]]\n",
      "====\n",
      "879  loss:  [[0.98816616]]\n",
      "====\n",
      "880  loss:  [[0.98990191]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "881  loss:  [[0.99109983]]\n",
      "====\n",
      "882  loss:  [[0.98662797]]\n",
      "====\n",
      "883  loss:  [[0.98891988]]\n",
      "====\n",
      "884  loss:  [[0.98822658]]\n",
      "====\n",
      "885  loss:  [[0.98655491]]\n",
      "====\n",
      "886  loss:  [[0.98697101]]\n",
      "====\n",
      "887  loss:  [[0.98707113]]\n",
      "====\n",
      "888  loss:  [[0.98476655]]\n",
      "====\n",
      "889  loss:  [[0.98547416]]\n",
      "====\n",
      "890  loss:  [[0.9859259]]\n",
      "====\n",
      "891  loss:  [[0.98412926]]\n",
      "====\n",
      "892  loss:  [[0.98306206]]\n",
      "====\n",
      "893  loss:  [[0.98461028]]\n",
      "====\n",
      "894  loss:  [[0.98283839]]\n",
      "====\n",
      "895  loss:  [[0.98209849]]\n",
      "====\n",
      "896  loss:  [[0.98297374]]\n",
      "====\n",
      "897  loss:  [[0.98128082]]\n",
      "====\n",
      "898  loss:  [[0.98151513]]\n",
      "====\n",
      "899  loss:  [[0.98000741]]\n",
      "====\n",
      "900  loss:  [[0.98085699]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "901  loss:  [[0.98035132]]\n",
      "====\n",
      "902  loss:  [[0.98003984]]\n",
      "====\n",
      "903  loss:  [[0.9780697]]\n",
      "====\n",
      "904  loss:  [[0.97797264]]\n",
      "====\n",
      "905  loss:  [[0.97964667]]\n",
      "====\n",
      "906  loss:  [[0.97723735]]\n",
      "====\n",
      "907  loss:  [[0.97631312]]\n",
      "====\n",
      "908  loss:  [[0.97762025]]\n",
      "====\n",
      "909  loss:  [[0.97653753]]\n",
      "====\n",
      "910  loss:  [[0.97429583]]\n",
      "====\n",
      "911  loss:  [[0.97617577]]\n",
      "====\n",
      "912  loss:  [[0.9755826]]\n",
      "====\n",
      "913  loss:  [[0.97323514]]\n",
      "====\n",
      "914  loss:  [[0.9746166]]\n",
      "====\n",
      "915  loss:  [[0.97393137]]\n",
      "====\n",
      "916  loss:  [[0.97240751]]\n",
      "====\n",
      "917  loss:  [[0.97342555]]\n",
      "====\n",
      "918  loss:  [[0.97198115]]\n",
      "====\n",
      "919  loss:  [[0.9717656]]\n",
      "====\n",
      "920  loss:  [[0.97180086]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "921  loss:  [[0.97104012]]\n",
      "====\n",
      "922  loss:  [[0.97058912]]\n",
      "====\n",
      "923  loss:  [[0.97033835]]\n",
      "====\n",
      "924  loss:  [[0.96923215]]\n",
      "====\n",
      "925  loss:  [[0.97013162]]\n",
      "====\n",
      "926  loss:  [[0.96821335]]\n",
      "====\n",
      "927  loss:  [[0.96940584]]\n",
      "====\n",
      "928  loss:  [[0.96727949]]\n",
      "====\n",
      "929  loss:  [[0.96769307]]\n",
      "====\n",
      "930  loss:  [[0.96751264]]\n",
      "====\n",
      "931  loss:  [[0.96651505]]\n",
      "====\n",
      "932  loss:  [[0.96768957]]\n",
      "====\n",
      "933  loss:  [[0.96498066]]\n",
      "====\n",
      "934  loss:  [[0.96592701]]\n",
      "====\n",
      "935  loss:  [[0.96573981]]\n",
      "====\n",
      "936  loss:  [[0.96403209]]\n",
      "====\n",
      "937  loss:  [[0.96557467]]\n",
      "====\n",
      "938  loss:  [[0.96346342]]\n",
      "====\n",
      "939  loss:  [[0.96213674]]\n",
      "====\n",
      "940  loss:  [[0.96541963]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "941  loss:  [[0.96283863]]\n",
      "====\n",
      "942  loss:  [[0.96095606]]\n",
      "====\n",
      "943  loss:  [[0.96304198]]\n",
      "====\n",
      "944  loss:  [[0.9608697]]\n",
      "====\n",
      "945  loss:  [[0.96165366]]\n",
      "====\n",
      "946  loss:  [[0.96213777]]\n",
      "====\n",
      "947  loss:  [[0.95897697]]\n",
      "====\n",
      "948  loss:  [[0.96005505]]\n",
      "====\n",
      "949  loss:  [[0.95976118]]\n",
      "====\n",
      "950  loss:  [[0.95910764]]\n",
      "====\n",
      "951  loss:  [[0.95897401]]\n",
      "====\n",
      "952  loss:  [[0.95812279]]\n",
      "====\n",
      "953  loss:  [[0.95835779]]\n",
      "====\n",
      "954  loss:  [[0.95691119]]\n",
      "====\n",
      "955  loss:  [[0.9581299]]\n",
      "====\n",
      "956  loss:  [[0.9561462]]\n",
      "====\n",
      "957  loss:  [[0.95632108]]\n",
      "====\n",
      "958  loss:  [[0.95680332]]\n",
      "====\n",
      "959  loss:  [[0.95536553]]\n",
      "====\n",
      "960  loss:  [[0.95545307]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "961  loss:  [[0.95536892]]\n",
      "====\n",
      "962  loss:  [[0.95407212]]\n",
      "====\n",
      "963  loss:  [[0.95442971]]\n",
      "====\n",
      "964  loss:  [[0.95509176]]\n",
      "====\n",
      "965  loss:  [[0.95172373]]\n",
      "====\n",
      "966  loss:  [[0.95402682]]\n",
      "====\n",
      "967  loss:  [[0.95369125]]\n",
      "====\n",
      "968  loss:  [[0.95155554]]\n",
      "====\n",
      "969  loss:  [[0.95175363]]\n",
      "====\n",
      "970  loss:  [[0.95121746]]\n",
      "====\n",
      "971  loss:  [[0.95295925]]\n",
      "====\n",
      "972  loss:  [[0.9494381]]\n",
      "====\n",
      "973  loss:  [[0.95067557]]\n",
      "====\n",
      "974  loss:  [[0.95145925]]\n",
      "====\n",
      "975  loss:  [[0.94733242]]\n",
      "====\n",
      "976  loss:  [[0.95113619]]\n",
      "====\n",
      "977  loss:  [[0.94999912]]\n",
      "====\n",
      "978  loss:  [[0.94635582]]\n",
      "====\n",
      "979  loss:  [[0.94986164]]\n",
      "====\n",
      "980  loss:  [[0.94747549]]\n",
      "====\n",
      "inference\n",
      "1024\n",
      "981  loss:  [[0.94767335]]\n",
      "====\n",
      "982  loss:  [[0.9475335]]\n",
      "====\n",
      "983  loss:  [[0.94708665]]\n",
      "====\n",
      "984  loss:  [[0.94640375]]\n",
      "====\n",
      "985  loss:  [[0.94577361]]\n",
      "====\n",
      "986  loss:  [[0.94703374]]\n",
      "====\n",
      "987  loss:  [[0.94531763]]\n",
      "====\n",
      "988  loss:  [[0.94427474]]\n",
      "====\n",
      "989  loss:  [[0.945327]]\n",
      "====\n",
      "990  loss:  [[0.94441651]]\n",
      "====\n",
      "991  loss:  [[0.94408796]]\n",
      "====\n",
      "992  loss:  [[0.94428855]]\n",
      "====\n",
      "993  loss:  [[0.94271748]]\n",
      "====\n",
      "994  loss:  [[0.94361604]]\n",
      "====\n",
      "995  loss:  [[0.94316154]]\n",
      "====\n",
      "996  loss:  [[0.94106335]]\n",
      "====\n",
      "997  loss:  [[0.94356958]]\n",
      "====\n",
      "998  loss:  [[0.94134516]]\n",
      "====\n",
      "999  loss:  [[0.94021395]]\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "\n",
    "  total = 0\n",
    "\n",
    "  for i in range(len(X)):\n",
    "    x = X[i:i+1,:].T\n",
    "    # y = Y[i:i+1,:]\n",
    "    y = Y[i:i+1,:]\n",
    "\n",
    "    y_pred, L = net.forward_backward(x,y,1e-2)\n",
    "\n",
    "    # print(y_pred, '- gt:', y)\n",
    "    # print(y)\n",
    "    # print (L)\n",
    "    # print(\"=====\")\n",
    "\n",
    "    total += L\n",
    "\n",
    "  print (epoch , ' loss: ', total)\n",
    "  print (\"====\")\n",
    "\n",
    "  if epoch%20==0:\n",
    "    inference()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyO48unSgGqu"
   },
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    x = X[i:i+1,:].T\n",
    "    y = Y[i,0]\n",
    "\n",
    "    y_pred = net.forward(x)\n",
    "\n",
    "    y_pred = y_pred[0,0]\n",
    "\n",
    "    y_pred_list.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1RwneO0gbbF",
    "outputId": "86bb0f11-904f-43fc-edf8-4ba430482b8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(Y, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKbvLfraNca1"
   },
   "outputs": [],
   "source": [
    "# 100  loss:  [[79.19130256]]  - using randn as weights\n",
    "# 100  loss:  [[26.3380848]] - using rand as weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03mljwXsZDsM",
    "outputId": "aae60f8c-53ee-4613-b33d-2b10c201b08e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdbPuR0bZtQX",
    "outputId": "e5bd8be1-ad75-4abb-db88-758136045e10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBYCXJgjOzEL",
    "outputId": "098724ed-72ad-40ee-d50b-c433919af772"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)\n",
    "# 96 correct beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kwe8nII5EKl5",
    "outputId": "b46910aa-c04e-4465-d97c-7a4683eea858"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Trained model parameters:\n",
      "Input layer size: 10\n",
      "Output layer size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create the MLP model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(16,), max_iter=1000, random_state=42, solver='sgd', learning_rate_init = 1e-2)\n",
    "\n",
    "# Train the model\n",
    "mlp_model.fit(X, Y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp_model.predict(X)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# You can also access the trained model parameters\n",
    "print(\"Trained model parameters:\")\n",
    "print(\"Input layer size:\", mlp_model.n_features_in_)\n",
    "print(\"Output layer size:\", mlp_model.n_outputs_)\n",
    "# print(\"Hidden layer sizes:\", mlp_model.hidden_layer_sizes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eF9vHL74kaBk",
    "outputId": "787b8f77-77e9-4818-b5b2-afdbf916521d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96875"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "992/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UkdYjLmdkdfQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
